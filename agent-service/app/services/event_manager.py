"""
Agent äº‹ä»¶ç®¡ç†å™¨

è´Ÿè´£äº‹ä»¶çš„åˆ›å»ºã€å­˜å‚¨å’Œæ¨é€
æ”¯æŒ SSE (Server-Sent Events) å®æ—¶æµå¼æ¨é€
é›†æˆ EventPersistence å®ç°æ•°æ®åº“æŒä¹…åŒ–
"""
import asyncio
import json
import logging
from typing import Optional, Dict, Any, List, Set
from datetime import datetime, timezone
from dataclasses import dataclass, field
from loguru import logger
from collections import deque
import uuid
import time
import re

logger = logging.getLogger(__name__)

# éœ€è¦èŠ‚æµçš„äº‹ä»¶ç±»å‹ï¼ˆé«˜é¢‘ç‡äº‹ä»¶ï¼‰
THROTTLED_EVENT_TYPES = {
    'thinking', 'llm_thought', 'thinking_token'
}

# éœ€è¦æ‰¹å¤„ç†çš„äº‹ä»¶ç±»å‹
BATCHABLE_EVENT_TYPES = {
    'thinking', 'llm_thought'
}

# æ‰¹å¤„ç†é…ç½®
BATCH_MAX_SIZE = 10  # æœ€å¤§æ‰¹å¤„ç†æ•°é‡
BATCH_MAX_WAIT_MS = 100  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
THROTTLE_INTERVAL_MS = 50  # èŠ‚æµé—´éš”ï¼ˆæ¯«ç§’ï¼‰

# UTF-8 æ— æ•ˆå­—ç¬¦æ¸…ç†æ¨¡å¼
INVALID_UTF8_PATTERN = re.compile(r'[^\x00-\x7F\x80-\xFF\u0100-\uFFFF]')


def _clean_utf8(text: str) -> str:
    """æ¸…ç†å­—ç¬¦ä¸²ä¸­çš„æ— æ•ˆ UTF-8 å­—ç¬¦"""
    if not isinstance(text, str):
        return text
    # ç§»é™¤æ§åˆ¶å­—ç¬¦ï¼ˆä¿ç•™æ¢è¡Œã€åˆ¶è¡¨ç¬¦ï¼‰
    cleaned = INVALID_UTF8_PATTERN.sub('', text)
    # è¿›ä¸€æ­¥æ¸…ç†æ§åˆ¶å­—ç¬¦
    cleaned = ''.join(char for char in cleaned if char == '\n' or char == '\t' or not (ord(char) < 32))
    return cleaned


def _sanitize_event_data(event_data: Dict[str, Any]) -> Dict[str, Any]:
    """é€’å½’æ¸…ç†äº‹ä»¶æ•°æ®ä¸­çš„æ— æ•ˆ UTF-8 å­—ç¬¦"""
    cleaned = {}
    for key, value in event_data.items():
        if isinstance(value, str):
            cleaned[key] = _clean_utf8(value)
        elif isinstance(value, dict):
            cleaned[key] = _sanitize_event_data(value)
        elif isinstance(value, list):
            cleaned[key] = [_sanitize_event_data(item) if isinstance(item, dict) else _clean_utf8(item) if isinstance(item, str) else item for item in value]
        else:
            cleaned[key] = value
    return cleaned


@dataclass
class AgentEventData:
    """Agent äº‹ä»¶æ•°æ®"""
    event_type: str
    phase: Optional[str] = None
    message: Optional[str] = None
    tool_name: Optional[str] = None
    tool_input: Optional[Dict[str, Any]] = None
    tool_output: Optional[Dict[str, Any]] = None
    tool_duration_ms: Optional[int] = None
    finding_id: Optional[str] = None
    tokens_used: int = 0
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": str(uuid.uuid4()),
            "event_type": self.event_type,
            "phase": self.phase,
            "message": self.message,
            "tool_name": self.tool_name,
            "tool_input": self.tool_input,
            "tool_output": self.tool_output,
            "tool_duration_ms": self.tool_duration_ms,
            "finding_id": self.finding_id,
            "tokens_used": self.tokens_used,
            "metadata": self.metadata,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }


class AgentEventEmitter:
    """
    Agent äº‹ä»¶å‘å°„å™¨
    ç”¨äºåœ¨ Agent æ‰§è¡Œè¿‡ç¨‹ä¸­å‘å°„äº‹ä»¶
    """

    def __init__(self, task_id: str, event_manager: 'EventManager'):
        self.task_id = task_id
        self.event_manager = event_manager
        self._sequence = 0
        self._current_phase = None

    async def emit(self, event_data: AgentEventData):
        """å‘å°„äº‹ä»¶"""
        self._sequence += 1
        event_data.phase = event_data.phase or self._current_phase

        await self.event_manager.add_event(
            task_id=self.task_id,
            sequence=self._sequence,
            **event_data.to_dict()
        )

    async def emit_phase_start(self, phase: str, message: Optional[str] = None):
        """å‘å°„é˜¶æ®µå¼€å§‹äº‹ä»¶"""
        self._current_phase = phase
        await self.emit(AgentEventData(
            event_type="phase_start",
            phase=phase,
            message=message or f"å¼€å§‹ {phase} é˜¶æ®µ",
        ))

    async def emit_phase_complete(self, phase: str, message: Optional[str] = None):
        """å‘å°„é˜¶æ®µå®Œæˆäº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="phase_complete",
            phase=phase,
            message=message or f"{phase} é˜¶æ®µå®Œæˆ",
        ))

    async def emit_thinking(self, message: str, metadata: Optional[Dict] = None):
        """å‘å°„æ€è€ƒäº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="thinking",
            message=message,
            metadata=metadata,
        ))

    async def emit_llm_thought(self, thought: str, iteration: int = 0):
        """å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶"""
        display = thought[:500] + "..." if len(thought) > 500 else thought
        await self.emit(AgentEventData(
            event_type="llm_thought",
            message=f"ğŸ’­ {display}",
            metadata={"thought": thought, "iteration": iteration},
        ))

    async def emit_llm_decision(self, decision: str, reason: str = ""):
        """å‘å°„ LLM å†³ç­–äº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="llm_decision",
            message=f"ğŸ’¡ {decision}" + (f" ({reason})" if reason else ""),
            metadata={"decision": decision, "reason": reason},
        ))

    async def emit_llm_action(self, action: str, action_input: Dict):
        """å‘å°„ LLM åŠ¨ä½œäº‹ä»¶"""
        input_str = json.dumps(action_input, ensure_ascii=False)[:200]
        await self.emit(AgentEventData(
            event_type="llm_action",
            message=f"âš¡ {action}\n   å‚æ•°: {input_str}",
            metadata={"action": action, "action_input": action_input},
        ))

    async def emit_tool_call(
        self,
        tool_name: str,
        tool_input: Dict[str, Any],
        message: Optional[str] = None,
    ):
        """å‘å°„å·¥å…·è°ƒç”¨äº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="tool_call",
            tool_name=tool_name,
            tool_input=tool_input,
            message=message or f"è°ƒç”¨å·¥å…·: {tool_name}",
        ))

    async def emit_tool_result(
        self,
        tool_name: str,
        tool_output: Any,
        duration_ms: int,
        message: Optional[str] = None,
    ):
        """å‘å°„å·¥å…·ç»“æœäº‹ä»¶"""
        # å¤„ç†è¾“å‡ºï¼Œç¡®ä¿å¯åºåˆ—åŒ–
        if hasattr(tool_output, 'to_dict'):
            output_data = tool_output.to_dict()
        elif isinstance(tool_output, str):
            output_data = {"result": tool_output[:2000]}
        else:
            output_data = {"result": str(tool_output)[:2000]}

        await self.emit(AgentEventData(
            event_type="tool_result",
            tool_name=tool_name,
            tool_output=output_data,
            tool_duration_ms=duration_ms,
            message=message or f"å·¥å…· {tool_name} æ‰§è¡Œå®Œæˆ ({duration_ms}ms)",
        ))

    async def emit_finding(
        self,
        finding_id: str,
        title: str,
        severity: str,
        vulnerability_type: str,
        is_verified: bool = False,
    ):
        """å‘å°„æ¼æ´å‘ç°äº‹ä»¶"""
        event_type = "finding_verified" if is_verified else "finding_new"
        await self.emit(AgentEventData(
            event_type=event_type,
            finding_id=finding_id,
            message=f"{'âœ… å·²éªŒè¯' if is_verified else 'ğŸ” æ–°å‘ç°'}: [{severity.upper()}] {title}",
            metadata={
                "id": finding_id,
                "title": title,
                "severity": severity,
                "vulnerability_type": vulnerability_type,
                "is_verified": is_verified,
            },
        ))

    async def emit_info(self, message: str, metadata: Optional[Dict] = None):
        """å‘å°„ä¿¡æ¯äº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="info",
            message=message,
            metadata=metadata,
        ))

    async def emit_warning(self, message: str, metadata: Optional[Dict] = None):
        """å‘å°„è­¦å‘Šäº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="warning",
            message=message,
            metadata=metadata,
        ))

    async def emit_error(self, message: str, metadata: Optional[Dict] = None):
        """å‘å°„é”™è¯¯äº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="error",
            message=message,
            metadata=metadata,
        ))

    async def emit_status(self, status: str, message: Optional[str] = None):
        """å‘å°„çŠ¶æ€æ›´æ–°äº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="status",
            message=message or f"çŠ¶æ€æ›´æ–°: {status}",
            metadata={"status": status},
        ))

    async def emit_complete(
        self,
        summary: str,
        findings_count: int,
        security_score: Optional[float] = None,
    ):
        """å‘å°„ä»»åŠ¡å®Œæˆäº‹ä»¶"""
        await self.emit(AgentEventData(
            event_type="task_complete",
            message=summary,
            metadata={
                "findings_count": findings_count,
                "security_score": security_score,
            },
        ))


class EventManager:
    """
    äº‹ä»¶ç®¡ç†å™¨

    ç®¡ç† Agent äº‹ä»¶çš„å­˜å‚¨å’Œæµå¼æ¨é€
    æ”¯æŒäº‹ä»¶æ‰¹å¤„ç†å’ŒèŠ‚æµä¼˜åŒ–
    é›†æˆ EventPersistence å®ç°æ•°æ®åº“æŒä¹…åŒ–
    """

    def __init__(self, persistence=None):
        """
        åˆå§‹åŒ–äº‹ä»¶ç®¡ç†å™¨

        Args:
            persistence: EventPersistence å®ä¾‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€å•ä¾‹ï¼‰
        """
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
        from app.services.event_persistence import get_event_persistence

        # æ¯ä¸ªä»»åŠ¡çš„äº‹ä»¶é˜Ÿåˆ—
        self._event_queues: Dict[str, deque] = {}
        # æ¯ä¸ªä»»åŠ¡çš„è®¢é˜…è€…
        self._subscribers: Dict[str, List[asyncio.Queue]] = {}
        # æŒä¹…åŒ–çš„äº‹ä»¶ï¼ˆç”¨äºå†å²æŸ¥è¯¢ï¼‰- ç°åœ¨ä»…ä½œä¸ºå†…å­˜ç¼“å­˜
        self._persistent_events: Dict[str, List[Dict]] = {}
        # æ¯ä¸ª task çš„åºåˆ—å·
        self._sequences: Dict[str, int] = {}
        self._lock = asyncio.Lock()

        # æ€§èƒ½ä¼˜åŒ–ç›¸å…³
        self._last_emit_time: Dict[str, Dict[str, float]] = {}  # {task_id: {event_type: timestamp}}
        self._batch_buffers: Dict[str, List[Dict]] = {}  # {task_id: [events]}
        self._batch_tasks: Dict[str, asyncio.Task] = {}  # {task_id: task}
        self._dedup_cache: Dict[str, Set[str]] = {}  # {task_id: set(event_ids)}

        # æ•°æ®åº“æŒä¹…åŒ–æœåŠ¡
        self._persistence = persistence or get_event_persistence()
        logger.info("[EventManager] åˆå§‹åŒ–å®Œæˆï¼Œå·²é›†æˆæ•°æ®åº“æŒä¹…åŒ–")

    def create_queue(self, task_id: str, max_size: int = 1000):
        """åˆ›å»ºä»»åŠ¡äº‹ä»¶é˜Ÿåˆ—"""
        if task_id not in self._event_queues:
            self._event_queues[task_id] = deque(maxlen=max_size)
            self._subscribers[task_id] = []
            self._persistent_events[task_id] = []
            self._sequences[task_id] = 0
            # åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–æ•°æ®ç»“æ„
            self._last_emit_time[task_id] = {}
            self._batch_buffers[task_id] = []
            self._dedup_cache[task_id] = set()
            logger.info(f"[EventManager] Created event queue for task {task_id}")

    def _should_throttle(self, task_id: str, event_type: str) -> bool:
        """æ£€æŸ¥äº‹ä»¶æ˜¯å¦åº”è¯¥è¢«èŠ‚æµ"""
        if event_type not in THROTTLED_EVENT_TYPES:
            return False

        now = time.time()
        last_time = self._last_emit_time.get(task_id, {}).get(event_type, 0)
        time_since_last = (now - last_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

        if time_since_last < THROTTLE_INTERVAL_MS:
            return True
        return False

    async def _flush_batch(self, task_id: str):
        """åˆ·æ–°æ‰¹å¤„ç†ç¼“å†²åŒº"""
        if task_id not in self._batch_buffers:
            return

        buffer = self._batch_buffers[task_id]
        if not buffer:
            return

        # æ‰¹é‡æ¨é€äº‹ä»¶
        for event in buffer:
            await self._push_to_subscribers(task_id, event)

        self._batch_buffers[task_id] = []
        logger.debug(f"[EventManager] Flushed batch for {task_id}, size: {len(buffer)}")

    async def _push_to_subscribers(self, task_id: str, event: Dict):
        """æ¨é€äº‹ä»¶åˆ°è®¢é˜…è€…"""
        for queue in self._subscribers.get(task_id, []):
            try:
                await queue.put(event)
            except Exception as e:
                logger.warning(f"[EventManager] Failed to push event to subscriber: {e}")

    async def add_event(self, task_id: str, sequence: int = 0, **event_data):
        """
        æ·»åŠ äº‹ä»¶åˆ°é˜Ÿåˆ—ï¼ˆæ”¯æŒèŠ‚æµå’Œæ‰¹å¤„ç†ï¼‰

        Args:
            task_id: ä»»åŠ¡ ID
            sequence: åºåˆ—å·ï¼ˆ0 è¡¨ç¤ºè‡ªåŠ¨åˆ†é…ï¼‰
            **event_data: äº‹ä»¶æ•°æ®
        """
        event_type = event_data.get("event_type", "")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦èŠ‚æµ
        if self._should_throttle(task_id, event_type):
            logger.debug(f"[EventManager] Throttled event {event_type} for {task_id}")
            return  # è·³è¿‡æ­¤äº‹ä»¶

        async with self._lock:
            if task_id not in self._event_queues:
                self.create_queue(task_id)

            # å¦‚æœ sequence ä¸º 0ï¼Œè‡ªåŠ¨åˆ†é…ä¸‹ä¸€ä¸ªåºåˆ—å·
            if sequence == 0:
                self._sequences[task_id] += 1
                sequence = self._sequences[task_id]
            else:
                # æ›´æ–°åºåˆ—å·
                if sequence > self._sequences[task_id]:
                    self._sequences[task_id] = sequence

            # æ›´æ–°æœ€åå‘é€æ—¶é—´
            self._last_emit_time[task_id][event_type] = time.time()

            # å»é‡æ£€æŸ¥
            event_id = event_data.get("id", str(uuid.uuid4()))
            if event_id in self._dedup_cache.get(task_id, set()):
                logger.debug(f"[EventManager] Duplicated event {event_id} for {task_id}")
                return

            # æ·»åŠ åˆ°é˜Ÿåˆ—
            event = {
                "id": event_id,
                "task_id": task_id,
                "sequence": sequence,
                **event_data
            }

            # æ¸…ç†æ— æ•ˆ UTF-8 å­—ç¬¦
            try:
                event = _sanitize_event_data(event)
            except Exception as e:
                logger.warning(f"[EventManager] æ¸…ç†äº‹ä»¶æ•°æ®å¤±è´¥: {e}")

            self._event_queues[task_id].append(event)
            self._persistent_events[task_id].append(event)
            self._dedup_cache[task_id].add(event_id)

            # å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä¸é˜»å¡ï¼‰
            try:
                # å‡†å¤‡æŒä¹…åŒ–æ•°æ®
                persistence_event = {
                    "id": event.get("id"),
                    "audit_id": task_id,  # task_id åœ¨æŒä¹…åŒ–å±‚ä½œä¸º audit_id
                    "agent_type": event.get("agent_type", "unknown"),
                    "event_type": event.get("event_type"),
                    "sequence": sequence,
                    "timestamp": event.get("timestamp", datetime.now(timezone.utc).isoformat()),
                    "message": event.get("message"),
                    "data": event,  # å­˜å‚¨å®Œæ•´äº‹ä»¶æ•°æ®
                }
                asyncio.create_task(self._persistence.save_event(persistence_event))
            except Exception as e:
                logger.warning(f"[EventManager] å¼‚æ­¥ä¿å­˜äº‹ä»¶åˆ°æ•°æ®åº“å¤±è´¥: {e}")

            # æ‰¹å¤„ç†é€»è¾‘
            if event_type in BATCHABLE_EVENT_TYPES:
                # æ·»åŠ åˆ°æ‰¹å¤„ç†ç¼“å†²åŒº
                self._batch_buffers[task_id].append(event)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ‰¹å¤„ç†
                buffer_size = len(self._batch_buffers[task_id])
                if buffer_size >= BATCH_MAX_SIZE:
                    await self._flush_batch(task_id)
                elif buffer_size == 1:
                    # åˆ›å»ºè‡ªåŠ¨åˆ·æ–°ä»»åŠ¡
                    if task_id in self._batch_tasks:
                        self._batch_tasks[task_id].cancel()

                    async def flush_after_delay():
                        await asyncio.sleep(BATCH_MAX_WAIT_MS / 1000)
                        await self._flush_batch(task_id)

                    self._batch_tasks[task_id] = asyncio.create_task(flush_after_delay())
            else:
                # éæ‰¹å¤„ç†äº‹ä»¶ç›´æ¥æ¨é€
                await self._push_to_subscribers(task_id, event)

    async def subscribe(self, task_id: str, after_sequence: int = 0) -> asyncio.Queue:
        """
        è®¢é˜…ä»»åŠ¡äº‹ä»¶æµ

        Args:
            task_id: ä»»åŠ¡ ID
            after_sequence: ä»å“ªä¸ªåºåˆ—å·å¼€å§‹

        Returns:
            äº‹ä»¶é˜Ÿåˆ—
        """
        async with self._lock:
            if task_id not in self._event_queues:
                self.create_queue(task_id)

            queue = asyncio.Queue()
            self._subscribers[task_id].append(queue)

            # å‘é€å†å²äº‹ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº† after_sequenceï¼‰
            if after_sequence > 0:
                # å…ˆä»å†…å­˜ç¼“å­˜è·å–
                for event in self._persistent_events.get(task_id, []):
                    if event.get("sequence", 0) > after_sequence:
                        await queue.put(event)

                # å¦‚æœå†…å­˜ä¸­æ²¡æœ‰è¶³å¤Ÿçš„äº‹ä»¶ï¼Œä»æ•°æ®åº“è·å–
                latest_mem_sequence = max(
                    [e.get("sequence", 0) for e in self._persistent_events.get(task_id, [])],
                    default=0
                )
                if latest_mem_sequence < after_sequence:
                    try:
                        # ä»æ•°æ®åº“æŸ¥è¯¢æ›´æ—©çš„äº‹ä»¶
                        db_events = self._persistence.get_events(
                            audit_id=task_id,
                            after_sequence=after_sequence,
                            limit=1000
                        )
                        # å‘é€æ•°æ®åº“ä¸­çš„äº‹ä»¶ï¼ˆåªå‘é€ä¸åœ¨å†…å­˜ä¸­çš„ï¼‰
                        for event in db_events:
                            if event.get("sequence", 0) > latest_mem_sequence:
                                # ä» data å­—æ®µä¸­æ¢å¤å®Œæ•´äº‹ä»¶
                                full_event = event.get("data", event)
                                await queue.put(full_event)
                        logger.info(f"[EventManager] ä»æ•°æ®åº“åŠ è½½äº† {len(db_events)} ä¸ªå†å²äº‹ä»¶")
                    except Exception as e:
                        logger.warning(f"[EventManager] ä»æ•°æ®åº“åŠ è½½å†å²äº‹ä»¶å¤±è´¥: {e}")

            logger.info(f"[EventManager] New subscriber for task {task_id}, after_sequence={after_sequence}")
            return queue

    async def unsubscribe(self, task_id: str, queue: asyncio.Queue):
        """å–æ¶ˆè®¢é˜…"""
        async with self._lock:
            if task_id in self._subscribers:
                if queue in self._subscribers[task_id]:
                    self._subscribers[task_id].remove(queue)
                    logger.info(f"[EventManager] Unsubscribed from task {task_id}")

    def get_events(self, task_id: str, after_sequence: int = 0, limit: int = 100) -> List[Dict]:
        """
        è·å–å†å²äº‹ä»¶

        Args:
            task_id: ä»»åŠ¡ ID
            after_sequence: èµ·å§‹åºåˆ—å·
            limit: æœ€å¤§æ•°é‡

        Returns:
            äº‹ä»¶åˆ—è¡¨
        """
        # å…ˆå°è¯•ä»å†…å­˜ç¼“å­˜è·å–
        mem_events = self._persistent_events.get(task_id, [])
        mem_filtered = [e for e in mem_events if e.get("sequence", 0) > after_sequence]

        # å¦‚æœå†…å­˜ä¸­æœ‰è¶³å¤Ÿçš„äº‹ä»¶ï¼Œç›´æ¥è¿”å›
        if len(mem_filtered) >= limit:
            return mem_filtered[-limit:]

        # å¦åˆ™ä»æ•°æ®åº“è¡¥å……
        try:
            latest_mem_seq = max([e.get("sequence", 0) for e in mem_events], default=0)
            db_events = self._persistence.get_events(
                audit_id=task_id,
                after_sequence=max(after_sequence, latest_mem_seq),
                limit=limit
            )

            # åˆå¹¶å†…å­˜å’Œæ•°æ®åº“çš„äº‹ä»¶
            all_events = mem_filtered.copy()
            seen_sequences = {e.get("sequence") for e in mem_filtered}

            for db_event in db_events:
                seq = db_event.get("sequence")
                if seq not in seen_sequences:
                    # ä» data å­—æ®µä¸­æ¢å¤å®Œæ•´äº‹ä»¶
                    full_event = db_event.get("data", db_event)
                    all_events.append(full_event)
                    seen_sequences.add(seq)

            # æŒ‰åºåˆ—å·æ’åºå¹¶è¿”å›æœ€å limit ä¸ª
            all_events.sort(key=lambda e: e.get("sequence", 0))
            return all_events[-limit:]

        except Exception as e:
            logger.warning(f"[EventManager] ä»æ•°æ®åº“è·å–äº‹ä»¶å¤±è´¥: {e}ï¼Œè¿”å›å†…å­˜ç¼“å­˜")
            return mem_filtered[-limit:]

    def get_latest_sequence(self, task_id: str) -> int:
        """è·å–æœ€æ–°åºåˆ—å·"""
        # å…ˆä»å†…å­˜è·å–
        mem_sequence = self._sequences.get(task_id, 0)

        # å¦‚æœå†…å­˜ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»æ•°æ®åº“è·å–
        if mem_sequence == 0:
            try:
                db_sequence = self._persistence.get_latest_sequence(audit_id=task_id)
                if db_sequence > 0:
                    logger.debug(f"[EventManager] ä»æ•°æ®åº“è·å–æœ€æ–°åºåˆ—å·: {db_sequence}")
                    return db_sequence
            except Exception as e:
                logger.warning(f"[EventManager] ä»æ•°æ®åº“è·å–åºåˆ—å·å¤±è´¥: {e}")

        return mem_sequence

    def cleanup(self, task_id: str):
        """æ¸…ç†ä»»åŠ¡äº‹ä»¶"""
        if task_id in self._event_queues:
            del self._event_queues[task_id]
        if task_id in self._subscribers:
            del self._subscribers[task_id]
        if task_id in self._persistent_events:
            del self._persistent_events[task_id]
        if task_id in self._sequences:
            del self._sequences[task_id]
        # æ¸…ç†æ€§èƒ½ä¼˜åŒ–æ•°æ®ç»“æ„
        if task_id in self._last_emit_time:
            del self._last_emit_time[task_id]
        if task_id in self._batch_buffers:
            del self._batch_buffers[task_id]
        if task_id in self._batch_tasks:
            self._batch_tasks[task_id].cancel()
            del self._batch_tasks[task_id]
        if task_id in self._dedup_cache:
            del self._dedup_cache[task_id]
        logger.info(f"[EventManager] Cleaned up task {task_id}")


# å…¨å±€äº‹ä»¶ç®¡ç†å™¨å®ä¾‹
event_manager = EventManager()
