"""
Analysis Agent - LLM é©±åŠ¨çš„æ·±åº¦åˆ†æè€…

è´Ÿè´£æ·±åº¦ä»£ç åˆ†æã€æ¼æ´æŒ–æ˜å’Œè¯¯æŠ¥è¿‡æ»¤

ä½¿ç”¨ MCP (Model Context Protocol) æ ‡å‡†å·¥å…·ç³»ç»Ÿ
"""
from typing import Dict, Any, List, Optional
from loguru import logger
import time

from app.agents.base import BaseAgent
from app.services.llm import LLMService, LLMProvider
from app.core.task_handoff import TaskHandoff, TaskHandoffBuilder
from app.services.prompt_builder import prompt_builder
from app.core.tool_loop import ToolCallLoop
from app.core.tool_adapter import create_tool_bridge
from app.core.monitoring import get_monitoring_system
from app.core.resilience import get_llm_circuit, get_llm_rate_limiter, get_tool_circuit


class AnalysisAgent(BaseAgent):
    """
    LLM é©±åŠ¨çš„ Analysis Agent

    ä½¿ç”¨ MCP æ ‡å‡†å·¥å…·ç³»ç»Ÿè¿›è¡Œä»£ç å®‰å…¨åˆ†æ
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(name="analysis", config=config)

        config = config or {}
        self._llm_config = config
        self._llm: Optional[LLMService] = None

        self.use_rag = config.get("use_rag", True)
        self.max_iterations = config.get("max_iterations", 15)
        self.max_findings_to_analyze = config.get("max_findings_to_analyze", 20)

        self._conversation: List[Dict[str, Any]] = []
        self._confirmed_findings: List[Dict[str, Any]] = []
        self._false_positives: List[str] = []

        # é›†æˆç›‘æ§å’Œå®¹é”™ç³»ç»Ÿ
        self._monitoring = get_monitoring_system()
        self._llm_circuit = get_llm_circuit()
        self._llm_rate_limiter = get_llm_rate_limiter()
        # å·¥å…·ç†”æ–­å™¨åœ¨éœ€è¦æ—¶åŠ¨æ€è·å–
        self._tool_circuits: Dict[str, Any] = {}

    @property
    def llm(self):
        """å»¶è¿Ÿåˆå§‹åŒ– LLM æœåŠ¡"""
        if self._llm is None:
            try:
                # 1. ä¼˜å…ˆä½¿ç”¨åˆå§‹åŒ–é…ç½®
                provider_str = self._llm_config.get("llm_provider") or "anthropic"
                model = self._llm_config.get("llm_model") or "claude-3-5-sonnet-20241022"
                api_key = self._llm_config.get("api_key")
                base_url = self._llm_config.get("base_url")

                # 2. å¦‚æœé…ç½®ç¼ºå¤±ï¼Œå°è¯•ä»è¿è¡Œæ—¶ä¸Šä¸‹æ–‡è·å–ï¼ˆç”± orchestrator ä¼ é€’ï¼‰
                if hasattr(self, '_runtime_context'):
                    # ä½¿ç”¨ or ç¡®ä¿ None å€¼ä¸ä¼šè¦†ç›–é»˜è®¤å€¼
                    ctx_api_key = self._runtime_context.get("api_key")
                    if ctx_api_key:
                        api_key = ctx_api_key
                    
                    ctx_provider = self._runtime_context.get("llm_provider")
                    if ctx_provider:
                        provider_str = ctx_provider
                        
                    ctx_model = self._runtime_context.get("llm_model")
                    if ctx_model:
                        model = ctx_model
                        
                    ctx_base_url = self._runtime_context.get("base_url")
                    if ctx_base_url:
                        base_url = ctx_base_url

                # Debug log for API Key presence (do not log the actual key)
                if api_key:
                    logger.info(f"[Analysis] API Key found (length: {len(str(api_key))})")
                else:
                    logger.warning("[Analysis] API Key NOT found in config or runtime_context")

                try:
                    provider = LLMProvider(provider_str)
                except ValueError:
                    logger.warning(f"æœªçŸ¥çš„ LLM provider '{provider_str}'ï¼Œä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼")
                    provider = LLMProvider.OPENAI

                self._llm = LLMService(
                    provider=provider,
                    model=model,
                    api_key=api_key,
                    base_url=base_url,
                )
            except Exception as e:
                logger.error(f"LLM æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
                raise ValueError(f"LLM æœåŠ¡æœªé…ç½®: {str(e)}")
        return self._llm

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œ LLM é©±åŠ¨çš„æ·±åº¦åˆ†æ"""
        audit_id = context.get("audit_id")
        scan_results = context.get("scan_results", [])

        # ä¿å­˜è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼ˆåŒ…å« LLM é…ç½®ï¼‰
        self._runtime_context = context

        # é‡ç½®çŠ¶æ€
        self._confirmed_findings = []
        self._false_positives = []

        logger.info(f"[Analysis Agent] å¼€å§‹åˆ†æï¼Œæ”¶åˆ° {len(scan_results)} ä¸ªæ‰«æç»“æœ")
        logger.info(f"[Analysis Agent] scan_results ç¤ºä¾‹: {scan_results[:3] if scan_results else 'None'}")

        # é™åˆ¶åˆ†ææ•°é‡
        if len(scan_results) > self.max_findings_to_analyze:
            self.think(f"æ‰«æç»“æœè¿‡å¤š ({len(scan_results)})ï¼Œä»…åˆ†æå‰ {self.max_findings_to_analyze} ä¸ªé«˜å±é—®é¢˜")
            scan_results = self._prioritize_findings(scan_results)[:self.max_findings_to_analyze]
            # æ›´æ–° context ä¸­çš„ scan_resultsï¼Œä»¥ä¾¿ prompt ä½¿ç”¨
            context["scan_results"] = scan_results

        # æ„å»ºä¸Šä¸‹æ–‡å’Œæç¤ºè¯
        analysis_context = await self._build_initial_context(context)
        system_prompt = await self._build_system_prompt(analysis_context)
        initial_message = self._format_initial_message(analysis_context)

        # ä½¿ç”¨ MCP å·¥å…·é€‚é…å™¨è·å–å·¥å…·å¤„ç†å™¨å’Œ LLM å·¥å…·åˆ—è¡¨
        # æ·»åŠ çŠ¶æ€åˆ°ä¸Šä¸‹æ–‡ä¾›å·¥å…·ä½¿ç”¨
        analysis_context["_confirmed_findings"] = self._confirmed_findings
        analysis_context["_false_positives"] = self._false_positives
        analysis_context["use_rag"] = self.use_rag

        # å­˜å‚¨æ‰«æç»“æœæ€»æ•°ï¼Œç”¨äºéªŒè¯æ˜¯å¦æ‰€æœ‰ç»“æœéƒ½è¢«å¤„ç†
        analysis_context["_total_scan_results"] = len(scan_results)
        analysis_context["_scan_results"] = scan_results

        tool_handlers, llm_tools = create_tool_bridge(context=analysis_context)

        self.think(f"å·²åŠ è½½ {len(llm_tools)} ä¸ª MCP å·¥å…·")
        logger.info(f"[Analysis Agent] å·²åŠ è½½ {len(llm_tools)} ä¸ªå·¥å…·: {[t.get('function', {}).get('name') for t in llm_tools]}")

        # åˆ›å»ºå¹¶è¿è¡Œå¾ªç¯
        loop = ToolCallLoop(
            llm=self.llm,
            tools=llm_tools,
            tool_handlers=tool_handlers,
            system_prompt=system_prompt,
            max_iterations=self.max_iterations,
            event_callback=self._publish_event
        )

        await loop.run(user_input=initial_message)
        self._conversation = loop.history

        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–å·¥å…·æ›´æ–°åçš„çŠ¶æ€
        self._confirmed_findings = analysis_context.get("_confirmed_findings", [])
        self._false_positives = analysis_context.get("_false_positives", [])

        # åˆ›å»ºä»»åŠ¡äº¤æ¥
        next_handoff = self._create_task_handoff(context)

        return {
            "status": "success",
            "result": self._confirmed_findings,
            "findings": self._confirmed_findings,
            "task_handoff": next_handoff.to_dict() if next_handoff else None,
            "stats": {
                "total_analyzed": len(scan_results),
                "confirmed": len(self._confirmed_findings),
                "false_positives": len(self._false_positives),
            },
        }

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    async def _build_initial_context(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        scan_results = input_data.get("scan_results", [])
        return {
            "audit_id": input_data.get("audit_id"),
            "project_id": input_data.get("project_id"),
            "project_path": input_data.get("project_path"),
            "scan_results": scan_results,
        }

    async def _build_system_prompt(self, context: Dict[str, Any]) -> str:
        return await prompt_builder.build_analysis_prompt(context)

    def _format_initial_message(self, context: Dict[str, Any]) -> str:
        scan_results = context["scan_results"]
        scan_count = len(scan_results)

        # æ ¼å¼åŒ–æ‰«æç»“æœåˆ—è¡¨
        results_list = ""
        for i, result in enumerate(scan_results[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            results_list += f"""
{i}. **{result.get('title', 'æœªå‘½å')}** ({result.get('severity', 'unknown').upper()})
   - ç±»å‹: {result.get('type', 'unknown')}
   - æ–‡ä»¶: {result.get('file_path', 'unknown')}
   - æè¿°: {result.get('description', 'æ— æè¿°')[:100]}...
"""

        if scan_count > 10:
            results_list += f"\n... è¿˜æœ‰ {scan_count - 10} ä¸ªæ‰«æç»“æœ\n"

        return f"""âš ï¸ **é‡è¦ï¼šä½ å¿…é¡»å¯¹æ¯ä¸ªæ‰«æç»“æœåšå‡ºæ˜ç¡®åˆ¤æ–­**

ä½ æœ‰ **{scan_count}** ä¸ªæ‰«æç»“æœéœ€è¦åˆ†æã€‚

## æ‰«æç»“æœåˆ—è¡¨
{results_list}

## âš ï¸ å¼ºåˆ¶è¦æ±‚

**å¯¹äºæ¯ä¸ªæ‰«æç»“æœï¼Œä½ å¿…é¡»ï¼š**
1. ä½¿ç”¨å·¥å…·åˆ†æä»£ç ï¼ˆread_fileã€get_ast_contextã€search_symbolç­‰ï¼‰
2. è°ƒç”¨ `report_finding` æŠ¥å‘Šç¡®è®¤çš„æ¼æ´
3. æˆ–è°ƒç”¨ `mark_false_positive` æ ‡è®°ä¸ºè¯¯æŠ¥
4. åˆ†æå®Œæ‰€æœ‰ç»“æœåï¼Œè°ƒç”¨ `finish_analysis` å®Œæˆä»»åŠ¡

## ğŸš« ä¸¥ç¦ä»¥ä¸‹è¡Œä¸º

- **ä¸¥ç¦**åœ¨æ²¡æœ‰åˆ†ææ‰€æœ‰æ‰«æç»“æœçš„æƒ…å†µä¸‹ç›´æ¥è°ƒç”¨ `finish_analysis`
- **ä¸¥ç¦**è·³è¿‡ä»»ä½•æ‰«æç»“æœ
- **ä¸¥ç¦**åŒæ—¶å¯¹å¤šä¸ªç»“æœåšå‡ºåˆ¤æ–­ï¼Œå¿…é¡»é€ä¸€åˆ†æ

## å¯ç”¨å·¥å…·

**ä»£ç åˆ†æå·¥å…·ï¼š**
- `read_file` - è¯»å–æ–‡ä»¶å†…å®¹
- `get_ast_context` - è·å–ASTä¸Šä¸‹æ–‡ï¼ˆåŒ…å«è°ƒç”¨å…³ç³»ï¼‰
- `search_symbol` - æœç´¢ç¬¦å·å®šä¹‰
- `get_code_structure` - è·å–ä»£ç ç»“æ„
- `list_files` - åˆ—å‡ºç›®å½•æ–‡ä»¶

**æ¼æ´åˆ¤å®šå·¥å…·ï¼š**
- `report_finding` - **å¿…é¡»è°ƒç”¨**æ¥æŠ¥å‘ŠçœŸå®æ¼æ´
- `mark_false_positive` - **å¿…é¡»è°ƒç”¨**æ¥æ ‡è®°è¯¯æŠ¥

**å®Œæˆå·¥å…·ï¼š**
- `finish_analysis` - åªåœ¨å¤„ç†å®Œæ‰€æœ‰ç»“æœåè°ƒç”¨

## å¼€å§‹åˆ†æ

è¯·ä»ç¬¬ä¸€ä¸ªæ‰«æç»“æœå¼€å§‹åˆ†æã€‚ä½ å¿…é¡»ï¼š
1. å…ˆä½¿ç”¨ä»£ç åˆ†æå·¥å…·æŸ¥çœ‹ç›¸å…³ä»£ç 
2. ç„¶åæ ¹æ®åˆ†æç»“æœè°ƒç”¨ `report_finding` æˆ– `mark_false_positive`
3. ç»§ç»­ä¸‹ä¸€ä¸ªç»“æœï¼Œç›´åˆ°æ‰€æœ‰ç»“æœéƒ½å¤„ç†å®Œæ¯•
4. æœ€åè°ƒç”¨ `finish_analysis` å®Œæˆä»»åŠ¡

**è®°ä½ï¼šæ¯ä¸ªæ‰«æç»“æœéƒ½å¿…é¡»è¢«å¤„ç†ï¼Œä¸èƒ½é—æ¼ä»»ä½•ä¸€ä¸ªï¼**
"""

    def _prioritize_findings(self, findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3, "info": 4}
        return sorted(
            findings,
            key=lambda f: severity_order.get(f.get("severity", "info").lower(), 5)
        )

    def _create_task_handoff(self, context: Dict[str, Any]) -> Optional[TaskHandoff]:
        if not self._confirmed_findings:
            return None
        return TaskHandoffBuilder(from_agent="analysis", to_agent="verification").summary(f"å‘ç° {len(self._confirmed_findings)} ä¸ªæ¼æ´").build()


# åˆ›å»ºå…¨å±€å®ä¾‹
analysis_agent = AnalysisAgent()
