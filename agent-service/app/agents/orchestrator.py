"""
Orchestrator Agent - LLM é©±åŠ¨çš„è‡ªä¸»ç¼–æ’è€…

ä½¿ç”¨ ReAct æ¨¡å¼ï¼š
- LLM æ€è€ƒå½“å‰çŠ¶æ€
- LLM å†³å®šä¸‹ä¸€æ­¥æ“ä½œ
- æ‰§è¡Œæ“ä½œï¼Œè·å–ç»“æœ
- LLM åˆ†æç»“æœï¼Œå†³å®šä¸‹ä¸€æ­¥
- é‡å¤ç›´åˆ° LLM å†³å®šå®Œæˆ
"""
from typing import Dict, Any, Optional, List
from loguru import logger
import time
import json
import re
from dataclasses import dataclass

from app.agents.base import BaseAgent
from app.services.llm import LLMService, LLMProvider
from app.services.llm.adapters.base import LLMMessage
from app.core.agent_registry import agent_registry
from app.core.graph_controller import agent_graph_controller
from app.services.rust_client import rust_client
from app.core.audit_phase import AuditPhaseManager, AuditPhase, get_phase_manager
from app.core.monitoring import get_monitoring_system
from app.core.resilience import get_llm_circuit, get_llm_rate_limiter, with_retry, LLM_RETRY_CONFIG


@dataclass
class AgentStep:
    """æ‰§è¡Œæ­¥éª¤"""
    thought: str
    action: str
    action_input: Dict[str, Any]
    observation: Optional[str] = None
    sub_agent_result: Optional[Any] = None


class OrchestratorAgent(BaseAgent):
    """
    ç¼–æ’ Agent - ReAct æ¨¡å¼

    LLM å…¨ç¨‹å‚ä¸å†³ç­–ï¼š
    1. LLM æ€è€ƒå½“å‰çŠ¶æ€
    2. LLM å†³å®šä¸‹ä¸€æ­¥æ“ä½œ
    3. æ‰§è¡Œæ“ä½œï¼Œè·å–ç»“æœ
    4. LLM åˆ†æç»“æœï¼Œå†³å®šä¸‹ä¸€æ­¥
    5. é‡å¤ç›´åˆ° LLM å†³å®šå®Œæˆ
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(name="orchestrator", config=config)

        config = config or {}
        self._llm_config = config
        self._llm: Optional[LLMService] = None

        self.max_iterations = config.get("max_iterations", 20)
        self._conversation: List[Dict[str, Any]] = []
        self._steps: List[AgentStep] = []
        self._all_findings: List[Dict[str, Any]] = []

        # è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
        self._runtime_context: Dict[str, Any] = {}

        # è·Ÿè¸ªå·²è°ƒåº¦çš„ Agent ä»»åŠ¡ï¼Œé¿å…é‡å¤è°ƒåº¦
        self._dispatched_tasks: Dict[str, int] = {}

        # ä¿å­˜å„ä¸ª Agent çš„å®Œæ•´ç»“æœ
        self._agent_results: Dict[str, Dict[str, Any]] = {}

        # è¿›åº¦è·Ÿè¸ª
        self._progress: int = 0

        # é›†æˆå®¡è®¡é˜¶æ®µç®¡ç†
        self._phase_manager: Optional[AuditPhaseManager] = None
        self._monitoring = get_monitoring_system()

        # å®¹é”™æœºåˆ¶
        self._llm_circuit = get_llm_circuit()
        self._llm_rate_limiter = get_llm_rate_limiter()

    def _update_progress(self, progress: int, message: str = ""):
        """æ›´æ–°å®¡è®¡è¿›åº¦"""
        self._progress = min(100, max(0, progress))
        if message:
            logger.info(f"[Orchestrator] è¿›åº¦: {self._progress}% - {message}")

        # å‘å¸ƒè¿›åº¦äº‹ä»¶åˆ°å‰ç«¯
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡æ¥å‘å¸ƒäº‹ä»¶ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        import asyncio

        async def _publish_progress():
            try:
                await self._publish_event("progress", {
                    "progress": self._progress,
                    "message": message
                })
            except Exception as e:
                logger.warning(f"[Orchestrator] å‘å¸ƒè¿›åº¦äº‹ä»¶å¤±è´¥: {e}")

        # å¦‚æœåœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­ï¼Œç›´æ¥åˆ›å»ºä»»åŠ¡
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                asyncio.create_task(_publish_progress())
        except:
            pass

    @property
    def llm(self):
        """å»¶è¿Ÿåˆå§‹åŒ– LLM æœåŠ¡"""
        if self._llm is None:
            try:
                provider_str = self._llm_config.get("llm_provider", "anthropic")
                try:
                    provider = LLMProvider(provider_str)
                except ValueError:
                    logger.warning(f"æœªçŸ¥çš„ LLM provider '{provider_str}'ï¼Œä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼")
                    provider = LLMProvider.OPENAI

                self._llm = LLMService(
                    provider=provider,
                    model=self._llm_config.get("llm_model", "claude-3-5-sonnet-20241022"),
                    api_key=self._llm_config.get("api_key"),
                    base_url=self._llm_config.get("base_url"),
                )
            except Exception as e:
                logger.error(f"LLM æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
                raise ValueError("LLM æœåŠ¡æœªé…ç½®ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½® API Key")
        return self._llm

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå®¡è®¡ç¼–æ’"""
        audit_id = context.get("audit_id")
        self.think(f"å¼€å§‹ç¼–æ’å®¡è®¡ä»»åŠ¡: {audit_id}")

        try:
            return await self._execute_with_llm(context)
        except Exception as e:
            logger.error(f"å®¡è®¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return {
                "agent": self.name,
                "status": "error",
                "error": str(e),
                "thinking_chain": self.thinking_chain
            }

    async def _execute_with_llm(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """LLM é©±åŠ¨çš„è‡ªä¸»ç¼–æ’ - ReAct æ¨¡å¼"""
        audit_id = context["audit_id"]
        project_id = context["project_id"]
        start_time = time.time()

        # åˆå§‹åŒ–é˜¶æ®µç®¡ç†å™¨
        self._phase_manager = get_phase_manager(audit_id)

        # æ³¨å†Œ Orchestrator
        orchestrator_id = f"orchestrator_{audit_id}"
        self.agent_id = orchestrator_id
        await agent_registry.register_agent(
            agent_id=orchestrator_id,
            agent_name="Orchestrator",
            agent_type="orchestrator",
            task=f"ç¼–æ’å®¡è®¡: {audit_id}",
            parent_id=None,
            agent_instance=self,
        )

        # ä¿å­˜è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
        self._runtime_context = {
            "audit_id": audit_id,
            "project_id": project_id,
            "project_path": context.get("project_path", ""),
            "audit_type": context.get("audit_type", "quick"),
            "config": context.get("config", {}),
        }

        # åˆå§‹åŒ–è¿›åº¦
        self._progress = 0
        self._update_progress(5, "åˆå§‹åŒ–å®¡è®¡ä»»åŠ¡")

        # åˆå§‹åŒ–å®¡è®¡é˜¶æ®µ
        await self._phase_manager.transition_to(AuditPhase.INITIALIZATION)
        await self._publish_event("thinking", {
            "message": f"å®¡è®¡é˜¶æ®µ: {self._phase_manager.current_phase.value}"
        })

        # æ„å»ºåˆå§‹æ¶ˆæ¯
        system_prompt = self._get_system_prompt()
        initial_message = self._format_initial_message(context)

        # åˆå§‹åŒ–å¯¹è¯å†å² - ä½¿ç”¨ LLMMessage å¯¹è±¡
        self._conversation = [
            LLMMessage(role="system", content=system_prompt),
            LLMMessage(role="user", content=initial_message),
        ]

        self._steps = []
        self._all_findings = []
        self._agent_results = {}
        self._dispatched_tasks = {}
        final_result = None

        # åˆå§‹åŒ–é”™è¯¯è®¡æ•°å™¨
        self._empty_response_count = 0
        self._format_error_count = 0

        self.think("Orchestrator Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»ç¼–æ’å†³ç­–...")
        await self._publish_event("thinking", {
            "message": "Orchestrator Agent å¯åŠ¨ï¼Œå¼€å§‹å®¡è®¡ç¼–æ’..."
        })

        try:
            # è½¬æ¢åˆ°è§„åˆ’é˜¶æ®µ
            await self._phase_manager.transition_to(AuditPhase.PLANNING)

            for iteration in range(self.max_iterations):
                self._iteration = iteration + 1
                logger.info(f"[Orchestrator] Iteration {iteration + 1}/{self.max_iterations}")

                # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–ï¼ˆå¸¦å®¹é”™æœºåˆ¶ï¼‰
                try:
                    logger.debug(f"[Orchestrator] å‘é€ LLM è¯·æ±‚ï¼Œå½“å‰å¯¹è¯å†å²é•¿åº¦: {len(self._conversation)}")

                    # åº”ç”¨é€Ÿç‡é™åˆ¶
                    await self._llm_rate_limiter.acquire()

                    # ä½¿ç”¨ç†”æ–­å™¨ä¿æŠ¤ LLM è°ƒç”¨
                    async def _llm_call():
                        return await self.llm.generate(messages=self._conversation)

                    response = await self._llm_circuit.call(_llm_call)
                    llm_output = response.content if hasattr(response, 'content') else ""

                    # è®°å½• LLM è°ƒç”¨æŒ‡æ ‡
                    await self._monitoring.record_llm_call(
                        model=self._llm_config.get("llm_model", "unknown"),
                        tokens_used=len(llm_output.split()),  # ç²—ç•¥ä¼°è®¡
                        duration=0.1,  # TODO: å®é™…æµ‹é‡
                        success=True,
                    )

                    logger.info(f"[Orchestrator] LLM å“åº”é•¿åº¦: {len(llm_output)} å­—ç¬¦")
                    logger.debug(f"[Orchestrator] LLM å“åº”å†…å®¹: {llm_output[:500]}...")
                except Exception as e:
                    logger.error(f"[Orchestrator] LLM call failed: {e}")

                    # è®°å½•é”™è¯¯
                    await self._monitoring.record_llm_call(
                        model=self._llm_config.get("llm_model", "unknown"),
                        tokens_used=0,
                        duration=0,
                        success=False,
                        error=e,
                    )

                    await self._publish_event("error", {
                        "message": f"LLM è°ƒç”¨å¤±è´¥: {str(e)}"
                    })
                    # è¿”å›é”™è¯¯çŠ¶æ€
                    return {
                        "agent": self.name,
                        "status": "error",
                        "error": f"LLM è°ƒç”¨å¤±è´¥: {str(e)}",
                        "thinking_chain": self.thinking_chain,
                    }

                if not llm_output or not llm_output.strip():
                    logger.warning(f"[Orchestrator] Empty LLM response")
                    # ç©ºå“åº”é‡è¯•æœºåˆ¶
                    empty_count = getattr(self, '_empty_response_count', 0) + 1
                    self._empty_response_count = empty_count
                    if empty_count >= 3:
                        error_msg = "è¿ç»­ 3 æ¬¡æ”¶åˆ°ç©ºå“åº”ï¼Œåœæ­¢å®¡è®¡"
                        await self._publish_event("error", {"message": error_msg})
                        return {
                            "agent": self.name,
                            "status": "error",
                            "error": error_msg,
                            "thinking_chain": self.thinking_chain,
                        }
                    # æç¤º LLM é‡æ–°è¾“å‡º
                    self._conversation.append(LLMMessage(role="user", content="è¯·è¾“å‡ºä½ çš„å†³ç­–ï¼šThought + Action + Action Input"))
                    continue

                # é‡ç½®ç©ºå“åº”è®¡æ•°
                self._empty_response_count = 0

                # è§£æ LLM çš„å†³ç­–
                step = self._parse_llm_response(llm_output)

                if step:
                    logger.info(f"[Orchestrator] è§£ææˆåŠŸ: action={step.action}, thought={step.thought[:50]}...")
                else:
                    logger.warning(f"[Orchestrator] è§£æå¤±è´¥ï¼Œæ— æ³•æå– Thought/Action")

                if not step:
                    # LLM è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®ï¼Œæç¤ºé‡è¯•
                    format_count = getattr(self, '_format_error_count', 0) + 1
                    self._format_error_count = format_count
                    if format_count >= 3:
                        error_msg = "è¿ç»­ 3 æ¬¡æ ¼å¼é”™è¯¯ï¼Œåœæ­¢å®¡è®¡"
                        await self._publish_event("error", {"message": error_msg})
                        return {
                            "agent": self.name,
                            "status": "error",
                            "error": error_msg,
                            "thinking_chain": self.thinking_chain,
                        }
                    await self._publish_event("thinking", {
                        "message": f"LLM è¾“å‡ºæ ¼å¼é”™è¯¯ ({format_count}/3)ï¼Œè¯·é‡æ–°è¾“å‡º"
                    })
                    self._conversation.append(LLMMessage(role="assistant", content=llm_output))
                    self._conversation.append(LLMMessage(role="user", content="è¯·æŒ‰ç…§è§„å®šæ ¼å¼è¾“å‡ºï¼šThought + Action + Action Input"))
                    continue

                # é‡ç½®æ ¼å¼é”™è¯¯è®¡æ•°
                self._format_error_count = 0

                self._steps.append(step)

                # å‘é€æ€è€ƒå†…å®¹äº‹ä»¶
                if step.thought:
                    self.think(step.thought)
                    await self._publish_event("thinking", {
                        "message": step.thought
                    })

                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation.append(LLMMessage(role="assistant", content=llm_output))

                # æ‰§è¡Œ LLM å†³å®šçš„æ“ä½œ
                if step.action == "finish":
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æ‰§è¡Œäº†å¿…è¦çš„æ­¥éª¤
                    if len(self._steps) <= 2 and iteration == 1:
                        # ç¬¬ä¸€æ­¥å°±è°ƒç”¨ finishï¼Œæ‹’ç»å¹¶è¦æ±‚å…ˆè°ƒåº¦ recon
                        logger.warning(f"[Orchestrator] LLM å°è¯•åœ¨ç¬¬ä¸€æ­¥ç›´æ¥è°ƒç”¨ finishï¼Œæ‹’ç»")
                        await self._publish_event("thinking", {
                            "message": "ä¸èƒ½ç›´æ¥å®Œæˆå®¡è®¡ï¼Œå¿…é¡»å…ˆè°ƒåº¦ recon Agent"
                        })
                        self._conversation.append(LLMMessage(role="user", content="""
ä½ ä¸èƒ½ç›´æ¥è°ƒç”¨ finishã€‚å¿…é¡»æŒ‰ç…§å®¡è®¡æµç¨‹æ‰§è¡Œï¼š

1. é¦–å…ˆè°ƒç”¨ dispatch_agent è°ƒåº¦ recon Agent
2. ç„¶åæ ¹æ®ç»“æœè°ƒåº¦ analysis Agent
3. æœ€åæ‰èƒ½è°ƒç”¨ finish

è¯·é‡æ–°å¼€å§‹ï¼Œå…ˆè°ƒç”¨ recon Agentã€‚

ç¤ºä¾‹ï¼š
Thought: æˆ‘éœ€è¦å…ˆäº†è§£é¡¹ç›®çš„ç»“æ„å’ŒæŠ€æœ¯æ ˆ
Action: dispatch_agent
Action Input: {"agent": "recon", "task": "ä¾¦å¯Ÿé¡¹ç›®ç»“æ„å’ŒæŠ€æœ¯æ ˆ"}
"""))
                        continue

                    # LLM å†³å®šå®Œæˆå®¡è®¡
                    self.think("å®¡è®¡å®Œæˆï¼ŒLLM åˆ¤æ–­å®¡è®¡å·²å……åˆ†å®Œæˆ")
                    await self._publish_event("status", {
                        "status": "completed",
                        "message": f"å®¡è®¡å®Œæˆï¼Œå‘ç° {len(self._all_findings)} ä¸ªæ¼æ´"
                    })
                    final_result = step.action_input
                    break

                elif step.action == "dispatch_agent":
                    # LLM å†³å®šè°ƒåº¦å­ Agent
                    agent_name = step.action_input.get("agent", "")
                    task = step.task = step.action_input.get("task", "")

                    # æ ¹æ®agentç±»å‹è½¬æ¢å®¡è®¡é˜¶æ®µ
                    if agent_name == "recon":
                        await self._phase_manager.transition_to(AuditPhase.RECONNAISSANCE)
                        self._update_progress(15, f"å¼€å§‹ä¾¦å¯Ÿé¡¹ç›®ç»“æ„")
                    elif agent_name == "analysis":
                        await self._phase_manager.transition_to(AuditPhase.ANALYSIS)
                        self._update_progress(45, f"å¼€å§‹åˆ†ææ¼æ´")

                    self.think(f"è°ƒåº¦ {agent_name} Agent: {task[:100]}")
                    await self._publish_event("action", {
                        "message": f"è°ƒåº¦ {agent_name} Agent",
                        "agent": agent_name,
                        "task": task
                    })

                    try:
                        observation = await self._dispatch_agent(step.action_input)
                        step.observation = observation

                        # æ›´æ–°è¿›åº¦å’Œé˜¶æ®µ
                        if agent_name == "recon":
                            await self._phase_manager.transition_to(AuditPhase.ANALYSIS)
                            self._update_progress(35, "ä¾¦å¯Ÿå®Œæˆï¼Œå‡†å¤‡åˆ†æ")
                        elif agent_name == "analysis":
                            # åˆ†æå®Œæˆï¼Œä¸å†è¿›å…¥éªŒè¯é˜¶æ®µï¼Œç›´æ¥å‡†å¤‡å®Œæˆå®¡è®¡
                            await self._phase_manager.transition_to(AuditPhase.COMPLETE)
                            self._update_progress(95, "åˆ†æå®Œæˆï¼Œå®¡è®¡å·²å®Œæˆ")

                            # æ·»åŠ æç¤ºï¼Œå‘Šè¯‰LLMå¯ä»¥è°ƒç”¨finishäº†
                            observation = f"""{observation}

---

## ğŸ“Š åˆ†æå·²å®Œæˆ

åˆ†æAgentå·²å®Œæˆä»£ç å®¡è®¡ã€‚ç°åœ¨ä½ å¯ä»¥ï¼š

1. æŸ¥çœ‹ä¸Šè¿°åˆ†æç»“æœ
2. å¦‚æœæ»¡æ„ï¼Œè°ƒç”¨ `finish` å®Œæˆå®¡è®¡
3. å¦‚æœéœ€è¦æ›´å¤šåˆ†æï¼Œå¯ä»¥å†æ¬¡è°ƒåº¦ analysis Agent

**å»ºè®®ç›´æ¥è°ƒç”¨ finish å®Œæˆå®¡è®¡ã€‚**
"""
                            step.observation = observation
                    except Exception as e:
                        logger.error(f"[Orchestrator] Sub-agent {agent_name} failed: {e}")
                        observation = f"## {agent_name} Agent æ‰§è¡Œå¤±è´¥\n\né”™è¯¯: {str(e)}"
                        step.observation = observation
                        await self._publish_event("error", {
                            "message": f"{agent_name} Agent æ‰§è¡Œå¤±è´¥: {str(e)[:100]}"
                        })

                    # å‘é€è§‚å¯Ÿäº‹ä»¶
                    self.think(f"{agent_name} Agent æ‰§è¡Œå®Œæˆ")

                elif step.action == "summarize":
                    # LLM è¦æ±‚æ±‡æ€»
                    self.think("æ±‡æ€»å½“å‰å‘ç°")
                    await self._publish_event("thinking", {
                        "message": "æ±‡æ€»å½“å‰å‘ç°"
                    })
                    observation = self._summarize_findings()
                    step.observation = observation

                else:
                    observation = f"æœªçŸ¥æ“ä½œ: {step.action}ï¼Œå¯ç”¨æ“ä½œ: dispatch_agent, summarize, finish"
                    step.observation = observation
                    await self._publish_event("thinking", {
                        "message": observation
                    })

                # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                self._conversation.append(LLMMessage(role="user", content=f"Observation:\n{step.observation}"))

            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)

            # æ›´æ–°è¿›åº¦åˆ° 100%
            self._update_progress(100, "å®¡è®¡å®Œæˆ")

            await self._publish_event("status", {
                "status": "completed",
                "message": f"Orchestrator å®Œæˆ: {len(self._all_findings)} ä¸ªå‘ç°, {len(self._steps)} è½®å†³ç­–"
            })

            return {
                "agent": self.name,
                "status": "success",
                "result": {
                    "findings": self._all_findings,
                    "summary": final_result or self._generate_default_summary(),
                    "steps": [
                        {
                            "thought": s.thought,
                            "action": s.action,
                            "action_input": s.action_input,
                            "observation": s.observation[:500] if s.observation else None,
                        }
                        for s in self._steps
                    ],
                },
                "thinking_chain": self.thinking_chain,
                "duration_ms": duration_ms,
                "stats": {
                    "files_scanned": self._runtime_context.get("files_scanned", 0),
                    "findings_count": len(self._all_findings),
                }
            }

        except Exception as e:
            logger.error(f"Orchestrator execution failed: {e}", exc_info=True)
            return {
                "agent": self.name,
                "status": "error",
                "error": str(e),
                "thinking_chain": self.thinking_chain
            }

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ CTX-Audit çš„ç¼–æ’ Agentï¼Œè´Ÿè´£**è‡ªä¸»**åè°ƒæ•´ä¸ªå®‰å…¨å®¡è®¡æµç¨‹ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯æ•´ä¸ªå®¡è®¡æµç¨‹çš„**å¤§è„‘**ï¼Œä½ éœ€è¦ï¼š
1. è‡ªä¸»æ€è€ƒå’Œå†³ç­–
2. æ ¹æ®è§‚å¯Ÿç»“æœåŠ¨æ€è°ƒæ•´ç­–ç•¥
3. å†³å®šä½•æ—¶è°ƒç”¨å“ªä¸ªå­ Agent
4. åˆ¤æ–­ä½•æ—¶å®¡è®¡å®Œæˆ

## ä½ å¯ä»¥è°ƒåº¦çš„å­ Agent
1. **recon**: ä¿¡æ¯æ”¶é›† Agent - åˆ†æé¡¹ç›®ç»“æ„ã€æŠ€æœ¯æ ˆã€å…¥å£ç‚¹
2. **analysis**: åˆ†æ Agent - æ·±åº¦ä»£ç å®¡è®¡ã€æ¼æ´æ£€æµ‹

## ä½ å¯ä»¥ä½¿ç”¨çš„æ“ä½œ

### 1. è°ƒåº¦å­ Agent
```
Action: dispatch_agent
Action Input: {"agent": "recon", "task": "ä¾¦å¯Ÿé¡¹ç›®ç»“æ„å’ŒæŠ€æœ¯æ ˆ"}
```

### 2. æ±‡æ€»å‘ç°
```
Action: summarize
Action Input: {}
```

### 3. å®Œæˆå®¡è®¡
```
Action: finish
Action Input: {"conclusion": "å®¡è®¡ç»“è®º"}
```

## å·¥ä½œæ–¹å¼
æ¯ä¸€æ­¥ï¼Œä½ éœ€è¦ï¼š

1. **Thought**: åˆ†æå½“å‰çŠ¶æ€ï¼Œæ€è€ƒä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
2. **Action**: é€‰æ‹©ä¸€ä¸ªæ“ä½œ (dispatch_agent/summarize/finish)
3. **Action Input**: æä¾›æ“ä½œå‚æ•° (å¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON)

## è¾“å‡ºæ ¼å¼
æ¯ä¸€æ­¥å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼ˆç¦æ­¢ä½¿ç”¨ Markdown æ ¼å¼æ ‡è®°ï¼‰ï¼š

```
Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹]
Action: dispatch_agent
Action Input: {"agent": "recon", "task": "ä¾¦å¯Ÿé¡¹ç›®ç»“æ„å’ŒæŠ€æœ¯æ ˆ"}
```

## âš ï¸ é‡è¦æ ¼å¼è¦æ±‚

**ç¦æ­¢ä½¿ç”¨ Markdown æ ¼å¼æ ‡è®°ï¼** ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯çº¯æ–‡æœ¬æ ¼å¼ï¼š

âœ… æ­£ç¡®æ ¼å¼ï¼š
```
Thought: æˆ‘éœ€è¦å…ˆäº†è§£é¡¹ç›®ç»“æ„
Action: dispatch_agent
Action Input: {"agent": "recon", "task": "ä¾¦å¯Ÿé¡¹ç›®ç»“æ„å’ŒæŠ€æœ¯æ ˆ"}
```

âŒ é”™è¯¯æ ¼å¼ï¼ˆç¦æ­¢ä½¿ç”¨ï¼‰ï¼š
```
**Thought:** æˆ‘éœ€è¦å…ˆäº†è§£é¡¹ç›®ç»“æ„
**Action:** dispatch_agent
**Action Input:** {"agent": "recon", "task": "ä¾¦å¯Ÿé¡¹ç›®ç»“æ„å’ŒæŠ€æœ¯æ ˆ"}
```

## å®¡è®¡æµç¨‹è¦æ±‚

**ä½ å¿…é¡»æŒ‰ç…§ä»¥ä¸‹é¡ºåºæ‰§è¡Œå®¡è®¡ï¼Œä¸èƒ½è·³è¿‡æ­¥éª¤ï¼š**

1. **ç¬¬ä¸€æ­¥**ï¼šå¿…é¡»å…ˆè°ƒç”¨ `dispatch_agent` è°ƒåº¦ `recon` Agent æ¥äº†è§£é¡¹ç›®
2. **ç¬¬äºŒæ­¥**ï¼šæ ¹æ® recon ç»“æœï¼Œè°ƒåº¦ `analysis` Agent è¿›è¡Œæ·±åº¦åˆ†æ
3. **ç¬¬ä¸‰æ­¥**ï¼šå¦‚æœåˆ†ææœ‰å‘ç°ï¼Œå¯ä»¥å†æ¬¡è°ƒåº¦ analysis æˆ–ç›´æ¥å®Œæˆå®¡è®¡
4. **æœ€å**ï¼šè°ƒç”¨ `finish` å®Œæˆå®¡è®¡

**é‡è¦ï¼š**
- ä½ å¿…é¡»å…ˆè°ƒåº¦ recon Agentï¼Œä¸èƒ½ç›´æ¥è°ƒç”¨ finish
- æ¯ä¸ªæ­¥éª¤éƒ½è¦æ€è€ƒä¸ºä»€ä¹ˆè¿™ä¹ˆåš
- Action Input å¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼

## ç¤ºä¾‹æµç¨‹

```
Thought: æˆ‘éœ€è¦å…ˆäº†è§£é¡¹ç›®çš„ç»“æ„å’ŒæŠ€æœ¯æ ˆï¼Œä»¥ä¾¿è¿›è¡Œåç»­çš„å®‰å…¨å®¡è®¡
Action: dispatch_agent
Action Input: {"agent": "recon", "task": "åˆ†æé¡¹ç›®ç»“æ„ã€æŠ€æœ¯æ ˆå’Œå…¥å£ç‚¹"}

Observation: [recon ç»“æœ...]

Thought: é¡¹ç›®æ˜¯ Python Flask åº”ç”¨ï¼Œå‘ç°äº†ä¸€äº›é«˜é£é™©åŒºåŸŸã€‚ç°åœ¨æˆ‘éœ€è¦å¯¹è¿™äº›åŒºåŸŸè¿›è¡Œæ·±åº¦åˆ†æ
Action: dispatch_agent
Action Input: {"agent": "analysis", "task": "æ·±åº¦åˆ†æé«˜é£é™©åŒºåŸŸçš„ä»£ç å®‰å…¨é—®é¢˜"}

Observation: [analysis ç»“æœ...]

Thought: å·²å®Œæˆæ·±åº¦åˆ†æï¼Œå‘ç°äº† X ä¸ªæ¼æ´ã€‚å®¡è®¡å·¥ä½œå·²ç»å……åˆ†å®Œæˆ
Action: finish
Action Input: {"conclusion": "å®¡è®¡å®Œæˆï¼Œå…±å‘ç° X ä¸ªæ¼æ´"}
```

ç°åœ¨å¼€å§‹å®¡è®¡ï¼Œè¯·å…ˆè°ƒç”¨ recon Agentï¼"""

    def _format_initial_message(self, context: Dict[str, Any]) -> str:
        """æ„å»ºåˆå§‹æ¶ˆæ¯"""
        return f"""è¯·å¼€å§‹å¯¹ä»¥ä¸‹é¡¹ç›®è¿›è¡Œå®‰å…¨å®¡è®¡ã€‚

## é¡¹ç›®ä¿¡æ¯
- Project ID: {context.get("project_id", "unknown")}
- Audit ID: {context.get("audit_id", "unknown")}
- Audit Type: {context.get("audit_type", "quick")}

## å¯ç”¨å­ Agent
- recon: ä¿¡æ¯æ”¶é›† Agentï¼Œç”¨äºåˆ†æé¡¹ç›®ç»“æ„å’ŒæŠ€æœ¯æ ˆ
- analysis: åˆ†æ Agentï¼Œç”¨äºæ·±åº¦ä»£ç å®¡è®¡å’Œæ¼æ´æ£€æµ‹

## âš ï¸ é‡è¦æç¤º
ä½ å¿…é¡»æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ‰§è¡Œå®¡è®¡ï¼š
1. **é¦–å…ˆ**è°ƒç”¨ dispatch_agent è°ƒåº¦ recon Agent äº†è§£é¡¹ç›®
2. **ç„¶å**æ ¹æ®ç»“æœè°ƒåº¦ analysis Agent è¿›è¡Œåˆ†æ
3. **æœ€å**è°ƒç”¨ finish å®Œæˆå®¡è®¡

**ä¸èƒ½ç›´æ¥è°ƒç”¨ finishï¼å¿…é¡»å…ˆè°ƒåº¦ recon Agentï¼**

**æ³¨æ„ï¼šanalysis å®Œæˆåç›´æ¥è°ƒç”¨ finish å³å¯ï¼Œæ— éœ€éªŒè¯é˜¶æ®µã€‚**

è¯·ç«‹å³å¼€å§‹ï¼šé¦–å…ˆè¾“å‡ºä½ çš„æ€è€ƒï¼Œç„¶åè°ƒç”¨ dispatch_agent è°ƒåº¦ recon Agentã€‚

ç¤ºä¾‹ï¼š
Thought: æˆ‘éœ€è¦å…ˆäº†è§£é¡¹ç›®çš„ç»“æ„å’ŒæŠ€æœ¯æ ˆ
Action: dispatch_agent
Action Input: {{"agent": "recon", "task": "ä¾¦å¯Ÿé¡¹ç›®ç»“æ„å’ŒæŠ€æœ¯æ ˆ"}}"""

    def _parse_llm_response(self, response: str) -> Optional[AgentStep]:
        """è§£æ LLM å“åº”"""
        # é¢„å¤„ç† - ç§»é™¤ Markdown æ ¼å¼æ ‡è®°
        cleaned_response = response
        cleaned_response = re.sub(r'\*\*Action:\*\*', 'Action:', cleaned_response)
        cleaned_response = re.sub(r'\*\*Action Input:\*\*', 'Action Input:', cleaned_response)
        cleaned_response = re.sub(r'\*\*Thought:\*\*', 'Thought:', cleaned_response)

        # æå– Thought
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|$)', cleaned_response, re.DOTALL)
        thought = thought_match.group(1).strip() if thought_match else ""

        # æå– Action
        action_match = re.search(r'Action:\s*(\w+)', cleaned_response)
        if not action_match:
            return None
        action = action_match.group(1).strip()

        # æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Observation:|$)', cleaned_response, re.DOTALL)
        if not input_match:
            return None

        input_text = input_match.group(1).strip()
        # ç§»é™¤ markdown ä»£ç å—
        input_text = re.sub(r'```json\s*', '', input_text)
        input_text = re.sub(r'```\s*', '', input_text)

        try:
            action_input = json.loads(input_text)
        except json.JSONDecodeError:
            # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå°è¯•æå–åŸå§‹æ–‡æœ¬
            action_input = {"raw": input_text}

        return AgentStep(
            thought=thought,
            action=action,
            action_input=action_input,
        )

    async def _dispatch_agent(self, params: Dict[str, Any]) -> str:
        """è°ƒåº¦å­ Agent"""
        agent_name = params.get("agent", "")
        task = params.get("task", "")

        logger.info(f"[Orchestrator] Dispatching {agent_name} Agent: {task[:50]}...")

        # æ£€æŸ¥æ˜¯å¦é‡å¤è°ƒåº¦åŒä¸€ä¸ª Agent
        dispatch_count = self._dispatched_tasks.get(agent_name, 0)
        if dispatch_count >= 2:
            return f"""## é‡å¤è°ƒåº¦è­¦å‘Š

ä½ å·²ç»è°ƒåº¦ {agent_name} Agent {dispatch_count} æ¬¡äº†ã€‚

å¦‚æœä¹‹å‰çš„è°ƒåº¦æ²¡æœ‰è¿”å›æœ‰ç”¨çš„ç»“æœï¼Œè¯·è€ƒè™‘ï¼š
1. å°è¯•è°ƒåº¦å…¶ä»– Agent
2. ä½¿ç”¨ finish æ“ä½œç»“æŸå®¡è®¡å¹¶æ±‡æ€»å·²æœ‰å‘ç°

å½“å‰å·²æ”¶é›†çš„å‘ç°æ•°é‡: {len(self._all_findings)}
"""

        self._dispatched_tasks[agent_name] = dispatch_count + 1

        try:
            # åˆ›å»ºå­ Agent
            agent_id = await agent_graph_controller.create_agent(
                agent_type=agent_name,
                task=task,
                parent_id=self.agent_id,
            )

            # è·å– agent å®ä¾‹ï¼ˆä¸ä½¿ç”¨ to_dict è¿”å›çš„æ•°æ®ï¼‰
            agent = await agent_registry.get_agent_instance(agent_id)
            if not agent:
                return f"## è°ƒåº¦å¤±è´¥\n\né”™è¯¯: æ— æ³•è·å– Agent å®ä¾‹: {agent_id}"

            # æ„å»ºå­ Agent è¾“å…¥
            sub_input = {
                "audit_id": self._runtime_context.get("audit_id"),
                "project_id": self._runtime_context.get("project_id"),
                "project_path": self._runtime_context.get("project_path", ""),
                "task": task,
                "previous_results": {
                    "findings": self._all_findings,
                },
                # ä¼ é€’ä¹‹å‰ Agent çš„ç»“æœ
                **self._agent_results,
                # ä¼ é€’ LLM é…ç½®ç»™å­ Agent
                "llm_provider": self._llm_config.get("llm_provider"),
                "llm_model": self._llm_config.get("llm_model"),
                "api_key": self._llm_config.get("api_key"),
                "base_url": self._llm_config.get("base_url"),
            }

            # æ‰§è¡Œå­ Agent
            result = await agent.run(sub_input)

            if result.get("status") == "success":
                data = result.get("result", {})

                # ä¿å­˜ Agent ç»“æœ
                self._agent_results[agent_name] = data

                # æ”¶é›†å‘ç°
                findings = data.get("findings", [])
                if findings:
                    for finding in findings:
                        if isinstance(finding, dict):
                            # æ ‡å‡†åŒ–å‘ç°æ ¼å¼
                            normalized = self._normalize_finding(finding)
                            if normalized:
                                self._all_findings.append(normalized)

                # æ›´æ–°ç»Ÿè®¡
                if agent_name == "analysis":
                    self._runtime_context["files_scanned"] = data.get("files_analyzed", 0)

                # æ„å»ºè§‚å¯Ÿç»“æœ
                if agent_name == "recon":
                    # Recon è¿”å›çš„æ ¼å¼: project_info, structure, tech_stack, attack_surface, dependencies
                    structure = data.get('structure', {})
                    attack_surface = data.get('attack_surface', {})
                    tech_stack = data.get('tech_stack', {})
                    dependencies = data.get('dependencies', {})

                    # å°† attack_surface è½¬æ¢ä¸º scan_results æ ¼å¼ä¾› analysis agent ä½¿ç”¨
                    scan_results = []
                    for entry_point in attack_surface.get('entry_points', []):
                        scan_results.append({
                            "id": f"recon_{len(scan_results)}",
                            "title": f"æ½œåœ¨æ”»å‡»é¢: {entry_point.get('description', 'æœªçŸ¥')}",
                            "severity": entry_point.get('severity', 'medium'),
                            "file_path": entry_point.get('file', ''),
                            "type": entry_point.get('type', 'unknown'),
                            "description": entry_point.get('description', ''),
                            "source": "recon"
                        })

                    # ä¿å­˜ scan_results ä¾› analysis ä½¿ç”¨
                    self._agent_results['scan_results'] = scan_results
                    self._runtime_context['scan_results'] = scan_results

                    logger.info(f"[Orchestrator] Recon å®Œæˆï¼Œç”Ÿæˆ {len(scan_results)} ä¸ªæ‰«æå€™é€‰")

                    observation = f"""## Recon Agent æ‰§è¡Œç»“æœ

**çŠ¶æ€**: æˆåŠŸ

### é¡¹ç›®ç»“æ„
- æ–‡ä»¶æ•°: {len(structure.get('files', []))}
- ç›®å½•æ•°: {len(structure.get('directories', []))}

### æŠ€æœ¯æ ˆ
- è¯­è¨€: {tech_stack.get('languages', [])}
- æ¡†æ¶: {tech_stack.get('frameworks', [])}

### æ”»å‡»é¢åˆ†æ
- å…¥å£ç‚¹æ•°é‡: {len(attack_surface.get('entry_points', []))}
- API ç«¯ç‚¹: {len(attack_surface.get('api_endpoints', []))}
- ç”¨æˆ·è¾“å…¥ç‚¹: {len(attack_surface.get('user_inputs', []))}
- æ–‡ä»¶æ“ä½œ: {len(attack_surface.get('file_operations', []))}
- å‘½ä»¤æ‰§è¡Œ: {len(attack_surface.get('command_executions', []))}

### ä¾èµ–åˆ†æ
- ä¾èµ–åº“æ•°é‡: {dependencies.get('total_libraries', 0)}

### ç”Ÿæˆçš„æ‰«æå€™é€‰
å·²ç”Ÿæˆ {len(scan_results)} ä¸ªéœ€è¦åˆ†æçš„å€™é€‰åŒºåŸŸ
"""

                else:
                    observation = f"""## {agent_name} Agent æ‰§è¡Œç»“æœ

**çŠ¶æ€**: æˆåŠŸ
**å‘ç°æ•°é‡**: {len(findings)}

### å‘ç°æ‘˜è¦
"""
                    for i, f in enumerate(findings[:10]):
                        if isinstance(f, dict):
                            observation += f"""
{i+1}. [{f.get('severity', 'unknown')}] {f.get('title', 'Unknown')}
   - ç±»å‹: {f.get('vulnerability_type', 'unknown')}
   - æ–‡ä»¶: {f.get('file_path', 'unknown')}
"""

                    if len(findings) > 10:
                        observation += f"\n... è¿˜æœ‰ {len(findings) - 10} ä¸ªå‘ç°"

                if data.get("summary"):
                    observation += f"\n\n### Agent æ€»ç»“\n{data['summary']}"

                return observation
            else:
                return f"## {agent_name} Agent æ‰§è¡Œå¤±è´¥\n\né”™è¯¯: {result.get('error', 'Unknown error')}"

        except Exception as e:
            logger.error(f"Sub-agent dispatch failed: {e}", exc_info=True)
            return f"## è°ƒåº¦å¤±è´¥\n\né”™è¯¯: {str(e)}"

    def _normalize_finding(self, finding: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ ‡å‡†åŒ–å‘ç°æ ¼å¼"""
        normalized = dict(finding)

        # å¤„ç† file -> file_path
        if "file" in normalized and "file_path" not in normalized:
            normalized["file_path"] = normalized["file"]

        # å¤„ç† line -> line_start
        if "line" in normalized and "line_start" not in normalized:
            normalized["line_start"] = normalized["line"]

        # å¤„ç† type -> vulnerability_type
        if "type" in normalized and "vulnerability_type" not in normalized:
            type_val = normalized["type"]
            if type_val and type_val.lower() not in ["vulnerability", "finding", "issue"]:
                normalized["vulnerability_type"] = type_val

        # ç¡®ä¿ severity å­˜åœ¨
        if "severity" not in normalized:
            normalized["severity"] = "medium"

        # ç”Ÿæˆ title å¦‚æœä¸å­˜åœ¨
        if "title" not in normalized:
            vuln_type = normalized.get("vulnerability_type", "Unknown")
            file_path = normalized.get("file_path", "")
            if file_path:
                import os
                normalized["title"] = f"{vuln_type.replace('_', ' ').title()} in {os.path.basename(file_path)}"
            else:
                normalized["title"] = f"{vuln_type.replace('_', ' ').title()} Vulnerability"

        return normalized

    def _summarize_findings(self) -> str:
        """æ±‡æ€»å½“å‰å‘ç°"""
        if not self._all_findings:
            return "ç›®å‰è¿˜æ²¡æœ‰å‘ç°ä»»ä½•æ¼æ´ã€‚"

        # ç»Ÿè®¡
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        type_counts = {}

        for f in self._all_findings:
            if not isinstance(f, dict):
                continue

            sev = f.get("severity", "low")
            severity_counts[sev] = severity_counts.get(sev, 0) + 1

            vtype = f.get("vulnerability_type", "other")
            type_counts[vtype] = type_counts.get(vtype, 0) + 1

        summary = f"""## å½“å‰å‘ç°æ±‡æ€»

**æ€»è®¡**: {len(self._all_findings)} ä¸ªæ¼æ´

### ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
- Critical: {severity_counts['critical']}
- High: {severity_counts['high']}
- Medium: {severity_counts['medium']}
- Low: {severity_counts['low']}

### æ¼æ´ç±»å‹åˆ†å¸ƒ
"""
        for vtype, count in type_counts.items():
            summary += f"- {vtype}: {count}\n"

        summary += "\n### è¯¦ç»†åˆ—è¡¨\n"
        for i, f in enumerate(self._all_findings):
            if isinstance(f, dict):
                summary += f"{i+1}. [{f.get('severity')}] {f.get('title')} ({f.get('file_path')})\n"

        return summary

    def _generate_default_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆé»˜è®¤æ‘˜è¦"""
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}

        for f in self._all_findings:
            if isinstance(f, dict):
                sev = f.get("severity", "low")
                severity_counts[sev] = severity_counts.get(sev, 0) + 1

        return {
            "total_findings": len(self._all_findings),
            "severity_distribution": severity_counts,
            "conclusion": "å®¡è®¡å®Œæˆ",
        }


# åˆ›å»ºå…¨å±€å®ä¾‹
orchestrator_agent = OrchestratorAgent()
