"""
Recon Agent - ä¾¦å¯Ÿå…µï¼ˆå¢å¼ºç‰ˆï¼‰

è´Ÿè´£ä¿¡æ¯æ”¶é›†ã€é¡¹ç›®ç»“æ„åˆ†æå’Œæ”»å‡»é¢è¯†åˆ«
é›†æˆå¤–éƒ¨å®‰å…¨å·¥å…·å’Œæ•°æ®æµåˆ†æ
"""
from typing import Dict, Any, List, Optional, Set
from loguru import logger
from pathlib import Path

from app.agents.base import BaseAgent
from app.services.external_tools import (
    ExternalToolService,
    get_external_tool_service,
    ToolInfo,
)
from app.core.dataflow_analysis import (
    DataFlowAnalyzer,
    get_dataflow_analyzer,
    Vulnerability,
)


class ReconAgent(BaseAgent):
    """
    Recon Agent (å¢å¼ºç‰ˆ)

    èŒè´£ï¼š
    1. æ‰«æé¡¹ç›®ç›®å½•ç»“æ„
    2. è¯†åˆ«ç¼–ç¨‹è¯­è¨€å’Œæ¡†æ¶
    3. æ¨èå¹¶è¿è¡Œå¤–éƒ¨å®‰å…¨å·¥å…·
    4. æ‰§è¡Œæ•°æ®æµåˆ†æè¯†åˆ«é«˜é£é™©åŒºåŸŸ
    5. ç”Ÿæˆä¼˜å…ˆçº§æ’åºçš„æ‰«æç›®æ ‡åˆ—è¡¨

    å‚è€ƒ DeepAudit-3.0.0 å®ç°
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(name="recon", config=config)
        self._tool_service: Optional[ExternalToolService] = None
        self._dataflow_analyzer: Optional[DataFlowAnalyzer] = None

    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¾¦å¯Ÿä»»åŠ¡

        Args:
            context: ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«:
                - audit_id: å®¡è®¡ ID
                - project_id: é¡¹ç›® ID
                - project_path: é¡¹ç›®è·¯å¾„ï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¾¦å¯Ÿç»“æœ
        """
        project_id = context.get("project_id")
        self.think(f"å¼€å§‹é¡¹ç›®ä¾¦å¯Ÿ: {project_id}")

        # 1. è·å–é¡¹ç›®ä¿¡æ¯
        project_info = await self._get_project_info(project_id)
        raw_path = project_info.get("path", "")
        
        # æ™ºèƒ½è§£æé¡¹ç›®è·¯å¾„
        project_path = await self._resolve_project_path(raw_path)
        self.think(f"é¡¹ç›®è·¯å¾„: {project_path}")

        if not project_path:
            self.think("è­¦å‘Š: é¡¹ç›®è·¯å¾„ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œå®Œæ•´æ‰«æ")
            # å°è¯•ä½¿ç”¨ context ä¸­çš„ path
            if context.get("project_path"):
                 project_path = await self._resolve_project_path(context.get("project_path"))
                 self.think(f"å°è¯•ä½¿ç”¨ context è·¯å¾„: {project_path}")
            
            if not project_path:
                return {"error": "é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨"}

        # åˆå§‹åŒ–æœåŠ¡
        self._tool_service = get_external_tool_service(project_path)
        self._dataflow_analyzer = get_dataflow_analyzer()

        # 2. è¯†åˆ«æŠ€æœ¯æ ˆ
        tech_stack = await self._identify_tech_stack(project_path)
        self.think(f"è¯†åˆ«åˆ°è¯­è¨€: {tech_stack.get('languages', [])}")
        self.think(f"è¯†åˆ«åˆ°æ¡†æ¶: {tech_stack.get('frameworks', [])}")

        # 3. æ¨èå¹¶æ£€æŸ¥å¯ç”¨å·¥å…·
        recommended_tools = await self._recommend_tools(tech_stack)
        available_tools = await self._tool_service.get_available_tools()
        self.think(f"æ¨èå·¥å…·: {[t.name for t in recommended_tools]}")
        self.think(f"å¯ç”¨å·¥å…·: {[t.name for t in available_tools]}")

        # 4. è¿è¡Œå¤–éƒ¨å·¥å…·è¿›è¡Œå¿«é€Ÿæ‰«æ
        tool_findings = await self._scan_with_tools(recommended_tools, available_tools)
        self.think(f"å¤–éƒ¨å·¥å…·å‘ç° {len(tool_findings)} ä¸ªæ½œåœ¨é—®é¢˜")

        # 5. æå–é«˜é£é™©åŒºåŸŸ
        high_risk_areas = await self._extract_high_risk_areas(
            tool_findings, tech_stack, project_path
        )
        self.think(f"è¯†åˆ«åˆ° {len(high_risk_areas)} ä¸ªé«˜é£é™©åŒºåŸŸ")

        # 6. æ‰§è¡Œæ•°æ®æµåˆ†æ
        dataflow_findings = await self._run_dataflow_analysis(project_path, tech_stack)
        self.think(f"æ•°æ®æµåˆ†æå‘ç° {len(dataflow_findings)} ä¸ªæ½œåœ¨æ¼æ´")

        # 7. æ‰«æé¡¹ç›®ç»“æ„
        structure = await self._scan_structure(project_path)
        self.think(f"å‘ç° {len(structure.get('files', []))} ä¸ªæ–‡ä»¶")

        # 8. æå–æ”»å‡»é¢
        attack_surface = await self._extract_attack_surface(structure, tech_stack)
        self.think(f"å‘ç° {len(attack_surface.get('entry_points', []))} ä¸ªæ”»å‡»é¢å…¥å£ç‚¹")

        # 9. åˆ†æä¾èµ–
        dependencies = await self._analyze_dependencies(structure)
        self.think(f"å‘ç° {len(dependencies.get('libraries', []))} ä¸ªä¾èµ–åº“")

        # 10. è¯†åˆ«é«˜ä»·å€¼ç›®æ ‡ï¼ˆWeaponizationï¼‰
        hvt_targets = await self._identify_high_value_targets(project_path)
        self.think(f"è¯†åˆ«åˆ° {len(hvt_targets)} ä¸ªé«˜ä»·å€¼ç›®æ ‡æ–‡ä»¶")
        
        # åˆå¹¶åˆ° high_risk_areas
        for target in hvt_targets:
            high_risk_areas.append({
                "path": target["path"],
                "risk_score": 0.8,  # é«˜ä»·å€¼ç›®æ ‡é»˜è®¤é«˜é£é™©
                "reason": target["description"]
            })

        # 11. ç”Ÿæˆä¼˜å…ˆçº§æ’åºçš„æ‰«æç›®æ ‡
        prioritized_targets = self._prioritize_scan_targets(
            high_risk_areas, dataflow_findings, attack_surface
        )

        return {
            "project_info": project_info,
            "project_path": project_path, # è¿”å›è§£æåçš„è·¯å¾„
            "tech_stack": tech_stack,
            "recommended_tools": [t.name for t in recommended_tools],
            "available_tools": [t.name for t in available_tools],
            "tool_findings": tool_findings,
            "high_risk_areas": high_risk_areas,
            "dataflow_findings": dataflow_findings,
            "hvt_targets": hvt_targets,
            "structure": structure,
            "attack_surface": attack_surface,
            "dependencies": dependencies,
            "prioritized_targets": prioritized_targets,
        }

    async def _resolve_project_path(self, path_str: str) -> str:
        """æ™ºèƒ½è§£æé¡¹ç›®è·¯å¾„"""
        if not path_str:
            return ""
            
        try:
            # 1. ç›´æ¥è§£æ
            path = Path(path_str).resolve()
            if path.exists() and path.is_dir():
                return str(path)
                
            # 2. å°è¯•ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•è§£æ
            cwd = Path.cwd()
            path = (cwd / path_str).resolve()
            if path.exists() and path.is_dir():
                return str(path)

            # 3. å°è¯•ä¿®æ­£ ./data/projects è·¯å¾„é—®é¢˜
            # å¦‚æœå½“å‰åœ¨ agent-service ä¸‹ï¼Œè€Œè·¯å¾„åŒ…å« agent-service
            if "agent-service" in str(path):
                 new_path_str = str(path).replace("agent-service\\agent-service", "agent-service")
                 new_path = Path(new_path_str)
                 if new_path.exists() and new_path.is_dir():
                     return str(new_path)

            # 4. å°è¯•åˆ©ç”¨ Rust Client åæ¨è·¯å¾„ (æœ€åæ‰‹æ®µ)
            try:
                from app.services.rust_client import rust_client
                # å°è¯•è·å–æ–‡ä»¶åˆ—è¡¨ï¼Œçœ‹èƒ½ä¸èƒ½æ‹¿åˆ°çœŸå®è·¯å¾„
                files = await rust_client.list_files(path_str)
                if files:
                    first_file = files[0]
                    # first_file åº”è¯¥æ˜¯ç»å¯¹è·¯å¾„
                    # å°è¯•æ‰¾åˆ° path_str åœ¨ first_file ä¸­çš„ä½ç½®
                    # ä¾‹å¦‚ path_str="./data/projects/uuid", first_file="D:/.../data/projects/uuid/file"
                    # æˆ‘ä»¬å–æœ€åä¸€ä¸ªç›®å½•å (uuid)
                    
                    target_name = Path(path_str).name
                    # è§„èŒƒåŒ–åˆ†éš”ç¬¦ä»¥è¿›è¡Œå­—ç¬¦ä¸²åŒ¹é…
                    norm_first_file = first_file.replace("\\", "/")
                    if target_name in norm_first_file:
                        # æˆªå–åˆ° target_name ç»“æŸ
                        idx = norm_first_file.rfind(target_name)
                        if idx != -1:
                            real_path = norm_first_file[:idx + len(target_name)]
                            real_path_obj = Path(real_path)
                            if real_path_obj.exists() and real_path_obj.is_dir():
                                self.think(f"é€šè¿‡ Rust Client åæ¨è·¯å¾„æˆåŠŸ: {real_path}")
                                return str(real_path)
            except Exception as e:
                # åªæœ‰åœ¨æ‰¾ä¸åˆ°è·¯å¾„æ—¶æ‰è®°å½•è¿™ä¸ªï¼Œé¿å…å™ªéŸ³
                pass
             
            return ""
        except Exception as e:
            logger.warning(f"è·¯å¾„è§£æå¤±è´¥: {e}")
            return ""

    async def _identify_high_value_targets(self, project_path: str) -> List[Dict[str, Any]]:
        """è¯†åˆ«é«˜ä»·å€¼ç›®æ ‡æ–‡ä»¶ (Weaponization)"""
        project_dir = Path(project_path)
        targets = []
        
        # å®šä¹‰é«˜ä»·å€¼æ¨¡å¼
        patterns = {
            "config": [
                "config.py", "settings.py", ".env", "application.yml", "application.properties",
                "web.config", "uwsgi.ini", "nginx.conf", "docker-compose.yml", "Dockerfile",
                "k8s.yaml", "helm.yaml"
            ],
            "auth": [
                "*auth*", "*login*", "*user*", "*permission*", "*role*", "*jwt*", "*token*",
                "*middleware*", "*interceptor*", "*filter*", "*security*"
            ],
            "upload": [
                "*upload*", "*file*", "*image*", "*attachment*", "*import*", "*export*"
            ],
            "database": [
                "*schema*", "*migration*", "*model*", "*entity*", "*db*", "*database*", "*sql*"
            ],
            "api": [
                "*api*", "*route*", "*controller*", "*view*", "*endpoint*", "*handler*"
            ],
            "crypto": [
                "*crypto*", "*cipher*", "*encrypt*", "*decrypt*", "*key*", "*secret*"
            ]
        }
        
        self.think("æ­£åœ¨æ‰«æé«˜ä»·å€¼ç›®æ ‡æ–‡ä»¶...")
        
        # æ‰«æ (é™åˆ¶æ•°é‡ä»¥é˜²å¡æ­»)
        count = 0
        max_targets = 100
        
        for category, pattern_list in patterns.items():
            if count >= max_targets:
                break
                
            for pattern in pattern_list:
                try:
                    # ä½¿ç”¨ rglob é€’å½’æŸ¥æ‰¾
                    for file_path in project_dir.rglob(pattern):
                        if count >= max_targets:
                            break
                            
                        # è¿‡æ»¤å¿½ç•¥ç›®å½•
                        if any(p in str(file_path).replace("\\", "/") for p in [".git", "node_modules", "venv", ".venv", "__pycache__", "dist", "build", "target", "vendor", ".idea", ".vscode", "bin", "obj", "out"]):
                            continue
                            
                        if file_path.is_file():
                            try:
                                rel_path = str(file_path.relative_to(project_dir))
                                # é¿å…é‡å¤
                                if any(t["path"] == rel_path for t in targets):
                                    continue
                                    
                                targets.append({
                                    "path": rel_path,
                                    "category": category,
                                    "type": "high_value_file",
                                    "description": f"Potential {category} file: {rel_path}"
                                })
                                count += 1
                                
                                # å®æ—¶é€šçŸ¥å‘ç°
                                await self._publish_event("thinking", {
                                    "message": f"ğŸ¯ å‘ç°é«˜ä»·å€¼ç›®æ ‡: {rel_path} ({category})"
                                })
                            except:
                                pass
                except Exception as e:
                    logger.warning(f"Error scanning pattern {pattern}: {e}")
                            
        return targets

    async def _get_project_info(self, project_id: str) -> Dict[str, Any]:
        """è·å–é¡¹ç›®ä¿¡æ¯"""
        from app.services.rust_client import rust_client

        try:
            return await rust_client.get_project(project_id)
        except Exception as e:
            logger.warning(f"è·å–é¡¹ç›®ä¿¡æ¯å¤±è´¥: {e}")
            return {"id": project_id, "path": "unknown"}

    async def _identify_tech_stack(self, project_path: str) -> Dict[str, Any]:
        """
        è¯†åˆ«æŠ€æœ¯æ ˆ

        Args:
            project_path: é¡¹ç›®è·¯å¾„

        Returns:
            æŠ€æœ¯æ ˆä¿¡æ¯
        """
        languages = set()
        frameworks = set()
        package_managers = set()

        # è§„èŒƒåŒ–è·¯å¾„ï¼šè½¬æ¢ä¸ºç»å¯¹è·¯å¾„å¹¶è§„èŒƒåŒ–åˆ†éš”ç¬¦
        project_dir = Path(project_path).resolve()
        self.think(f"è§„èŒƒåŒ–åçš„é¡¹ç›®è·¯å¾„: {project_dir}")

        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not project_dir.exists():
            self.think(f"è­¦å‘Š: é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_dir}")
            return {
                "languages": [],
                "frameworks": [],
                "package_managers": [],
            }
            
        # å¿½ç•¥ç›®å½•åˆ—è¡¨
        ignored_dirs = {
            ".git", "node_modules", "venv", ".venv", "__pycache__", 
            "dist", "build", "target", "vendor", ".idea", ".vscode",
            "bin", "obj", "out"
        }

        # æ£€æŸ¥å¸¸è§æ–‡ä»¶è¯†åˆ«è¯­è¨€å’Œæ¡†æ¶
        check_files = [
            ("package.json", "JavaScript", ["Node.js"]),
            ("tsconfig.json", "TypeScript", ["Node.js"]),
            ("requirements.txt", "Python", ["Python/Pip"]),
            ("Pipfile", "Python", ["Pipenv"]),
            ("pyproject.toml", "Python", ["Poetry"]),
            ("setup.py", "Python", ["Python"]),
            ("pom.xml", "Java", ["Maven"]),
            ("build.gradle", "Java", ["Gradle"]),
            ("Cargo.toml", "Rust", ["Cargo"]),
            ("go.mod", "Go", ["Go Module"]),
            ("composer.json", "PHP", ["Composer"]),
            ("Gemfile", "Ruby", ["Bundler"]),
            ("pubspec.yaml", "Dart", ["Pub"]),
            ("mix.exs", "Elixir", ["Hex"]),
        ]

        found_files = []
        # é€’å½’æ£€æŸ¥é…ç½®æ–‡ä»¶ï¼ˆé™åˆ¶æ·±åº¦ï¼‰
        for file_name, lang, fw_list in check_files:
            try:
                # é¦–å…ˆæ£€æŸ¥æ ¹ç›®å½•
                if (project_dir / file_name).exists():
                    languages.add(lang)
                    frameworks.update(fw_list)
                    found_files.append(file_name)
                    self._update_package_managers(file_name, package_managers)
                else:
                    # å¦‚æœæ ¹ç›®å½•æ²¡æœ‰ï¼Œå°è¯•åœ¨å­ç›®å½•æŸ¥æ‰¾ï¼ˆæ·±åº¦2ï¼‰
                    # æ³¨æ„ï¼šrglob å¯èƒ½ä¼šå¾ˆæ…¢ï¼Œæ‰€ä»¥é™åˆ¶æŸ¥æ‰¾
                    matches = list(project_dir.glob(f"*/{file_name}")) + list(project_dir.glob(f"*/*/{file_name}"))
                    if matches:
                        # è¿‡æ»¤å¿½ç•¥ç›®å½•
                        valid_match = False
                        for match in matches:
                            if not any(d in match.parts for d in ignored_dirs):
                                valid_match = True
                                break
                        
                        if valid_match:
                            languages.add(lang)
                            frameworks.update(fw_list)
                            found_files.append(file_name)
                            self._update_package_managers(file_name, package_managers)
            except Exception:
                pass

        if found_files:
            self.think(f"æ‰¾åˆ°é…ç½®æ–‡ä»¶: {found_files}")

        # é€šè¿‡æ–‡ä»¶æ‰©å±•åè¡¥å……è¯­è¨€è¯†åˆ«
        extension_map = {
            ".py": "Python",
            ".js": "JavaScript",
            ".ts": "TypeScript",
            ".tsx": "TypeScript",
            ".jsx": "JavaScript",
            ".java": "Java",
            ".go": "Go",
            ".rs": "Rust",
            ".php": "PHP",
            ".rb": "Ruby",
            ".cs": "C#",
            ".cpp": "C++",
            ".c": "C",
            ".kt": "Kotlin",
            ".swift": "Swift",
        }

        # é™åˆ¶æ‰«ææ·±åº¦ï¼Œé¿å…æ‰«æè¿‡æ·±
        scanned_count = 0
        max_files = 1000  # å¢åŠ æ‰«æé™åˆ¶

        try:
            for file_path in project_dir.rglob("*"):
                if scanned_count >= max_files:
                    break
                
                # è¿‡æ»¤å¿½ç•¥ç›®å½•
                if any(d in file_path.parts for d in ignored_dirs):
                    continue

                if file_path.is_file():
                    scanned_count += 1
                    file_str = str(file_path)
                    for ext, lang in extension_map.items():
                        if file_str.endswith(ext):
                            languages.add(lang)
                            break
        except PermissionError as e:
            self.think(f"æ–‡ä»¶æ‰«ææƒé™é”™è¯¯: {e}")

        # æ£€æµ‹ Web æ¡†æ¶ (å¢å¼ºç‰ˆ)
        web_frameworks_map = {
            "app.py": "Flask",
            "wsgi.py": "Flask",
            "manage.py": "Django",
            "application.go": "Go Web Framework",
            "gin.go": "Gin",
            "main.go": "Go", # é€šç”¨
            "NestFactory": "NestJS", # å†…å®¹æ£€æµ‹å¯èƒ½å¤ªæ…¢ï¼Œè¿™é‡Œåªåšæ–‡ä»¶å
        }
        
        for fname, fw in web_frameworks_map.items():
             if (project_dir / fname).exists():
                 frameworks.add(fw)

        result = {
            "languages": sorted(list(languages)),
            "frameworks": sorted(list(frameworks)),
            "package_managers": sorted(list(package_managers)),
        }

        self.think(f"æŠ€æœ¯æ ˆè¯†åˆ«ç»“æœ - è¯­è¨€: {result['languages']}, æ¡†æ¶: {result['frameworks']}")
        return result

    def _update_package_managers(self, file_name: str, package_managers: Set[str]):
        """æ›´æ–°åŒ…ç®¡ç†å™¨é›†åˆ"""
        if file_name == "package.json":
            package_managers.add("npm")
        elif file_name == "requirements.txt":
            package_managers.add("pip")
        elif file_name == "Cargo.toml":
            package_managers.add("cargo")
        elif file_name == "go.mod":
            package_managers.add("go")
        elif file_name == "pom.xml":
            package_managers.add("maven")
        elif file_name == "build.gradle":
            package_managers.add("gradle")
        elif file_name == "Gemfile":
            package_managers.add("bundler")
        elif file_name == "composer.json":
            package_managers.add("composer")

    async def _recommend_tools(self, tech_stack: Dict[str, Any]) -> List[ToolInfo]:
        """
        æ ¹æ®æŠ€æœ¯æ ˆæ¨èå·¥å…·

        Args:
            tech_stack: æŠ€æœ¯æ ˆä¿¡æ¯

        Returns:
            æ¨èçš„å·¥å…·åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        """
        languages = tech_stack.get("languages", [])
        frameworks = tech_stack.get("frameworks", [])

        # å·¥å…·æ¨èè§„åˆ™
        recommendations = []

        # Semgrep - æ”¯æŒå¤šè¯­è¨€ï¼Œä¼˜å…ˆæ¨è
        recommendations.append("semgrep")

        # Gitleaks - æ‰€æœ‰é¡¹ç›®éƒ½éœ€è¦
        recommendations.append("gitleaks")

        # è¯­è¨€ç‰¹å®šå·¥å…·
        if "Python" in languages:
            recommendations.append("bandit")
            recommendations.append("safety")

        if any(lang in languages for lang in ["JavaScript", "TypeScript"]):
            recommendations.append("npm_audit")

        # åŒ…ç®¡ç†å™¨ç‰¹å®šå·¥å…·
        package_managers = tech_stack.get("package_managers", [])
        if "npm" in package_managers:
            recommendations.append("npm_audit")
        if "pip" in package_managers or "poetry" in package_managers:
            recommendations.append("safety")

        # å»é‡å¹¶ä¿æŒé¡ºåº
        seen = set()
        ordered_tools = []
        for tool in recommendations:
            if tool not in seen:
                seen.add(tool)
                ordered_tools.append(tool)

        # è·å–å·¥å…·ä¿¡æ¯
        all_tools = [
            ToolInfo(
                name="semgrep",
                description="é™æ€ä»£ç åˆ†æå·¥å…·ï¼Œæ”¯æŒå¤šç§è¯­è¨€",
                language=["*"],
                install_cmd="pip install semgrep",
                check_cmd=["semgrep", "--version"],
                priority=10,
            ),
            ToolInfo(
                name="bandit",
                description="Python å®‰å…¨æ¼æ´æ‰«æå·¥å…·",
                language=["python"],
                install_cmd="pip install bandit",
                check_cmd=["bandit", "--version"],
                priority=9,
            ),
            ToolInfo(
                name="safety",
                description="Python ä¾èµ–æ¼æ´æ‰«æå·¥å…·",
                language=["python"],
                install_cmd="pip install safety",
                check_cmd=["safety", "--version"],
                priority=7,
            ),
            ToolInfo(
                name="gitleaks",
                description="å¯†é’¥å’Œæ•æ„Ÿä¿¡æ¯æ£€æµ‹å·¥å…·",
                language=["*"],
                install_cmd="go install github.com/zricethezav/gitleaks/v8/cmd/gitleaks@latest",
                check_cmd=["gitleaks", "version"],
                priority=8,
            ),
            ToolInfo(
                name="npm_audit",
                description="Node.js ä¾èµ–æ¼æ´æ‰«æå·¥å…·",
                language=["javascript", "typescript"],
                install_cmd="",  # npm è‡ªå¸¦
                check_cmd=["npm", "--version"],
                priority=6,
            ),
        ]

        # æ„å»ºæ¨èå·¥å…·åˆ—è¡¨
        tool_map = {t.name: t for t in all_tools}
        return [tool_map[name] for name in ordered_tools if name in tool_map]

    async def _scan_with_tools(
        self,
        recommended_tools: List[ToolInfo],
        available_tools: List[ToolInfo],
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨æ¨èå·¥å…·è¿›è¡Œæ‰«æ

        Args:
            recommended_tools: æ¨èçš„å·¥å…·åˆ—è¡¨
            available_tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨

        Returns:
            å·¥å…·å‘ç°åˆ—è¡¨
        """
        all_findings = []

        # åªè¿è¡Œå¯ç”¨çš„å·¥å…·
        available_names = {t.name for t in available_tools}

        for tool_info in recommended_tools:
            if tool_info.name not in available_names:
                self.think(f"å·¥å…· {tool_info.name} ä¸å¯ç”¨ï¼Œè·³è¿‡")
                continue

            self.think(f"è¿è¡Œå·¥å…·: {tool_info.name}")

            try:
                result = await self._tool_service.run_tool_by_name(tool_info.name)

                if result and result.success:
                    self.think(f"å·¥å…· {tool_info.name} å‘ç° {len(result.findings)} ä¸ªé—®é¢˜")

                    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                    for finding in result.findings:
                        all_findings.append({
                            "tool": tool_info.name,
                            "severity": finding.get("severity", "medium"),
                            "title": finding.get("title", ""),
                            "description": finding.get("description", ""),
                            "file_path": finding.get("file_path", ""),
                            "line_number": finding.get("line_number", 0),
                            "rule_id": finding.get("rule_id", ""),
                            "cwe_ids": finding.get("cwe_ids", []),
                            "metadata": finding.get("metadata", {}),
                        })
                else:
                    self.think(f"å·¥å…· {tool_info.name} æ‰§è¡Œå¤±è´¥: {result.error if result else 'Unknown error'}")

            except Exception as e:
                logger.warning(f"è¿è¡Œå·¥å…· {tool_info.name} å¤±è´¥: {e}")

        return all_findings

    async def _extract_high_risk_areas(
        self,
        tool_findings: List[Dict[str, Any]],
        tech_stack: Dict[str, Any],
        project_path: str,
    ) -> List[Dict[str, Any]]:
        """
        ä»å·¥å…·å‘ç°ä¸­æå–é«˜é£é™©åŒºåŸŸ

        Args:
            tool_findings: å·¥å…·å‘ç°åˆ—è¡¨
            tech_stack: æŠ€æœ¯æ ˆä¿¡æ¯
            project_path: é¡¹ç›®è·¯å¾„

        Returns:
            é«˜é£é™©åŒºåŸŸåˆ—è¡¨ï¼ˆå¸¦æ–‡ä»¶è·¯å¾„å’Œè¡Œå·ï¼‰
        """
        high_risk_areas = []

        # æŒ‰æ–‡ä»¶åˆ†ç»„ç»Ÿè®¡é—®é¢˜
        file_issues = {}
        for finding in tool_findings:
            file_path = finding.get("file_path", "")
            if not file_path:
                continue

            severity = finding.get("severity", "medium")
            line_number = finding.get("line_number", 0)

            if file_path not in file_issues:
                file_issues[file_path] = {
                    "critical": [],
                    "high": [],
                    "medium": [],
                    "low": [],
                }

            if severity in file_issues[file_path]:
                file_issues[file_path][severity].append(line_number)

        # ç”Ÿæˆé«˜é£é™©åŒºåŸŸ
        for file_path, issues in file_issues.items():
            # ä¼˜å…ˆçº§è§„åˆ™
            priority = 0

            # æœ‰ critical é—®é¢˜
            if issues["critical"]:
                priority = 100 + len(issues["critical"])
            # æœ‰ high é—®é¢˜
            elif issues["high"]:
                priority = 70 + len(issues["high"])
            # æœ‰å¤šä¸ª medium é—®é¢˜
            elif len(issues["medium"]) >= 3:
                priority = 50 + len(issues["medium"])
            # æœ‰ medium é—®é¢˜
            elif issues["medium"]:
                priority = 30 + len(issues["medium"])

            if priority > 0:
                high_risk_areas.append({
                    "file_path": file_path,
                    "priority": priority,
                    "issues": issues,
                    "recommendation": "ä¼˜å…ˆåˆ†ææ­¤æ–‡ä»¶",
                })

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        high_risk_areas.sort(key=lambda x: x["priority"], reverse=True)

        # åªè¿”å›ä¼˜å…ˆçº§ >= 30 çš„åŒºåŸŸ
        return [area for area in high_risk_areas if area["priority"] >= 30]

    async def _run_dataflow_analysis(
        self,
        project_path: str,
        tech_stack: Dict[str, Any],
    ) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œæ•°æ®æµåˆ†æ

        Args:
            project_path: é¡¹ç›®è·¯å¾„
            tech_stack: æŠ€æœ¯æ ˆä¿¡æ¯

        Returns:
            æ•°æ®æµåˆ†æå‘ç°çš„æ¼æ´åˆ—è¡¨
        """
        languages = tech_stack.get("languages", [])

        # æ•°æ®æµåˆ†æä¸»è¦é’ˆå¯¹åŠ¨æ€è¯­è¨€
        target_languages = {"Python", "JavaScript", "TypeScript", "PHP", "Ruby"}
        if not any(lang in languages for lang in target_languages):
            self.think("é¡¹ç›®ä¸åŒ…å«æ”¯æŒæ•°æ®æµåˆ†æçš„è¯­è¨€ï¼Œè·³è¿‡")
            return []

        self.think("å¼€å§‹æ•°æ®æµåˆ†æ...")

        try:
            # åˆ†ææ•´ä¸ªé¡¹ç›®
            vulnerabilities = await self._dataflow_analyzer.analyze_project(
                project_path=project_path,
                file_patterns=None,  # åˆ†ææ‰€æœ‰æ–‡ä»¶
            )

            self.think(f"æ•°æ®æµåˆ†æå®Œæˆï¼Œå‘ç° {len(vulnerabilities)} ä¸ªæ½œåœ¨æ¼æ´")

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            findings = []
            for vuln in vulnerabilities:
                findings.append({
                    "tool": "dataflow",
                    "vulnerability_type": vuln.vuln_type,
                    "severity": vuln.severity,
                    "title": f"{vuln.vuln_type} in {Path(vuln.path.sink_location[0]).name}",
                    "description": vuln.description,
                    "file_path": vuln.path.sink_location[0],
                    "line_number": vuln.path.sink_location[1],
                    "source": vuln.source.name,
                    "sink": vuln.sink.name,
                    "sanitized": vuln.path.is_sanitized,
                    "confidence": vuln.path.confidence,
                    "cwe_ids": vuln.cwe_ids,
                    "recommendation": vuln.recommendation,
                })

            return findings

        except Exception as e:
            logger.warning(f"æ•°æ®æµåˆ†æå¤±è´¥: {e}")
            return []

    async def _scan_structure(self, project_path: str) -> Dict[str, Any]:
        """
        æ‰«æé¡¹ç›®ç»“æ„

        Args:
            project_path: é¡¹ç›®è·¯å¾„

        Returns:
            é¡¹ç›®ç»“æ„
        """
        from app.services.rust_client import rust_client

        files = []
        directories = []
        
        # å¿½ç•¥ç›®å½•åˆ—è¡¨
        ignored_dirs = {
            ".git", "node_modules", "venv", ".venv", "__pycache__", 
            "dist", "build", "target", "vendor", ".idea", ".vscode",
            "bin", "obj", "out"
        }

        try:
            items = await rust_client.list_files(project_path)
            for item in items:
                # è§„èŒƒåŒ–è·¯å¾„åˆ†éš”ç¬¦
                norm_item = item.replace("\\", "/")
                
                # è¿‡æ»¤å¿½ç•¥ç›®å½•
                # æ£€æŸ¥è·¯å¾„éƒ¨åˆ†ä¸­æ˜¯å¦åŒ…å«å¿½ç•¥ç›®å½•
                parts = norm_item.split("/")
                if any(part in ignored_dirs for part in parts):
                    continue

                full_path = item
                # ç®€å•åˆ¤æ–­ï¼šæœ‰åç¼€çš„æ˜¯æ–‡ä»¶
                if "." in item.split("/")[-1]:
                    files.append(full_path)
                else:
                    directories.append(full_path)

        except Exception as e:
            logger.warning(f"æ‰«æé¡¹ç›®ç»“æ„å¤±è´¥: {e}")

        return {"files": files, "directories": directories}

    async def _extract_attack_surface(
        self,
        structure: Dict[str, Any],
        tech_stack: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        æå–æ”»å‡»é¢

        Args:
            structure: é¡¹ç›®ç»“æ„
            tech_stack: æŠ€æœ¯æ ˆ

        Returns:
            æ”»å‡»é¢ä¿¡æ¯
        """
        entry_points = []
        user_inputs = []

        files = structure.get("files", [])

        # è¯†åˆ«æ½œåœ¨çš„æ”»å‡»é¢å…¥å£
        for file_path in files:
            file_name = file_path.split("/")[-1].lower()
            file_dir = "/".join(file_path.split("/")[:-1]).lower()

            # Web è·¯ç”±æ–‡ä»¶
            if any(keyword in file_dir or keyword in file_name
                   for keyword in ["route", "controller", "handler", "api", "view", "endpoint"]):
                entry_points.append({
                    "type": "web_route",
                    "file": file_path,
                    "description": "Web è·¯ç”±å®šä¹‰æ–‡ä»¶",
                })

            # è¡¨å•/è¾“å…¥å¤„ç†
            if any(keyword in file_name for keyword in ["form", "input", "upload", "submit"]):
                user_inputs.append({
                    "type": "user_input",
                    "file": file_path,
                    "description": "ç”¨æˆ·è¾“å…¥å¤„ç†æ–‡ä»¶",
                })

            # æ•°æ®åº“æŸ¥è¯¢
            if any(keyword in file_dir or keyword in file_name
                   for keyword in ["model", "query", "database", "db", "sql"]):
                entry_points.append({
                    "type": "database",
                    "file": file_path,
                    "description": "æ•°æ®åº“æ“ä½œæ–‡ä»¶",
                })

            # è®¤è¯/æˆæƒ
            if any(keyword in file_dir or keyword in file_name
                   for keyword in ["auth", "login", "permission", "access", "user", "session"]):
                entry_points.append({
                    "type": "auth",
                    "file": file_path,
                    "description": "è®¤è¯/æˆæƒæ–‡ä»¶",
                    "severity": "high",
                })

            # æ–‡ä»¶æ“ä½œ
            if any(keyword in file_dir or keyword in file_name
                   for keyword in ["file", "fs", "io", "upload", "download", "storage"]):
                entry_points.append({
                    "type": "file_operation",
                    "file": file_path,
                    "description": "æ–‡ä»¶æ“ä½œæ–‡ä»¶",
                })

            # å‘½ä»¤æ‰§è¡Œ
            if any(keyword in file_dir or keyword in file_name
                   for keyword in ["exec", "spawn", "shell", "command", "system", "subprocess"]):
                entry_points.append({
                    "type": "command_execution",
                    "file": file_path,
                    "description": "å‘½ä»¤æ‰§è¡Œç›¸å…³",
                    "severity": "high",
                })

        return {
            "entry_points": entry_points,
            "user_inputs": user_inputs,
            "file_operations": [e for e in entry_points if e["type"] == "file_operation"],
            "command_executions": [e for e in entry_points if e["type"] == "command_execution"],
        }

    async def _analyze_dependencies(self, structure: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æä¾èµ–åº“

        Args:
            structure: é¡¹ç›®ç»“æ„

        Returns:
            ä¾èµ–ä¿¡æ¯
        """
        libraries = []
        files = structure.get("files", [])

        # åˆ†æä¾èµ–æ–‡ä»¶
        for file_path in files:
            filename = file_path.split("/")[-1].lower()

            if filename == "package.json":
                libraries.extend(await self._parse_package_json(file_path))
            elif filename == "requirements.txt":
                libraries.extend(await self._parse_requirements_txt(file_path))

        return {
            "libraries": libraries,
            "total_libraries": len(libraries),
        }

    async def _parse_package_json(self, file_path: str) -> List[Dict[str, str]]:
        """è§£æ package.json"""
        from app.services.rust_client import rust_client

        try:
            content = await rust_client.read_file(file_path)
            import json
            data = json.loads(content)

            deps = data.get("dependencies", {})
            dev_deps = data.get("devDependencies", {})

            libraries = []
            for name, version in list(deps.items()) + list(dev_deps.items()):
                libraries.append({
                    "name": name,
                    "version": version,
                    "type": "production" if name in deps else "development",
                    "ecosystem": "npm",
                })

            return libraries
        except Exception as e:
            logger.warning(f"è§£æ package.json å¤±è´¥: {e}")
            return []

    async def _parse_requirements_txt(self, file_path: str) -> List[Dict[str, str]]:
        """è§£æ requirements.txt"""
        from app.services.rust_client import rust_client

        try:
            content = await rust_client.read_file(file_path)

            libraries = []
            for line in content.split("\n"):
                line = line.strip()
                if not line or line.startswith("#"):
                    continue

                # è§£æåŒ…åå’Œç‰ˆæœ¬
                parts = line.split(">=")[:1] if ">=" in line else \
                        line.split("==")[:1] if "==" in line else \
                        line.split("~")[:1] if "~" in line else \
                        [line]

                if parts:
                    libraries.append({
                        "name": parts[0].strip(),
                        "version": line.replace(parts[0], "").strip() or "unknown",
                        "type": "production",
                        "ecosystem": "pypi",
                    })

            return libraries
        except Exception as e:
            logger.warning(f"è§£æ requirements.txt å¤±è´¥: {e}")
            return []

    def _prioritize_scan_targets(
        self,
        high_risk_areas: List[Dict[str, Any]],
        dataflow_findings: List[Dict[str, Any]],
        attack_surface: Dict[str, Any],
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆä¼˜å…ˆçº§æ’åºçš„æ‰«æç›®æ ‡åˆ—è¡¨

        Args:
            high_risk_areas: é«˜é£é™©åŒºåŸŸ
            dataflow_findings: æ•°æ®æµåˆ†æå‘ç°
            attack_surface: æ”»å‡»é¢

        Returns:
            ä¼˜å…ˆçº§æ’åºçš„æ‰«æç›®æ ‡
        """
        targets = []

        # 1. æ•°æ®æµåˆ†æå‘ç°çš„æ¼æ´ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        for finding in dataflow_findings:
            if finding.get("severity") in ["critical", "high"]:
                targets.append({
                    "type": "dataflow_vulnerability",
                    "file_path": finding.get("file_path"),
                    "line_number": finding.get("line_number"),
                    "priority": 100,
                    "reason": f"æ•°æ®æµåˆ†æå‘ç°çš„ {finding.get('severity')} æ¼æ´",
                    "finding": finding,
                })

        # 2. é«˜é£é™©åŒºåŸŸ
        for area in high_risk_areas:
            targets.append({
                "type": "high_risk_area",
                "file_path": area.get("file_path"),
                "priority": area.get("priority", 50),
                "reason": f"å·¥å…·æ‰«æå‘ç° {area.get('priority')} ä¸ªé—®é¢˜",
                "issues": area.get("issues"),
            })

        # 3. è®¤è¯/æˆæƒå…¥å£ç‚¹
        for entry in attack_surface.get("entry_points", []):
            if entry.get("severity") == "high":
                targets.append({
                    "type": "auth_entry",
                    "file_path": entry.get("file"),
                    "priority": 70,
                    "reason": "è®¤è¯/æˆæƒç›¸å…³å…¥å£ç‚¹",
                })

        # 4. å‘½ä»¤æ‰§è¡Œå…¥å£ç‚¹
        for entry in attack_surface.get("command_executions", []):
            targets.append({
                "type": "command_execution",
                "file_path": entry.get("file"),
                "priority": 80,
                "reason": "å‘½ä»¤æ‰§è¡Œç›¸å…³ä»£ç ",
            })

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        targets.sort(key=lambda x: x["priority"], reverse=True)

        return targets


# åˆ›å»ºå…¨å±€å®ä¾‹
recon_agent = ReconAgent()
